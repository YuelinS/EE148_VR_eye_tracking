{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "# from learning_curve import myplot\n",
    "import pickle\n",
    "from EyeTrackingV2 import EyeTrackingDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "parser.add_argument('--batch-size', type=int, default=200, metavar='N',\n",
    "                    help='input batch size for training (default: 64)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=128, metavar='N',\n",
    "                    help='input batch size for testing (default: 1000)')\n",
    "parser.add_argument('--epochs', type=int, default=1, metavar='N',\n",
    "                    help='number of epochs to train (default: 14)')\n",
    "parser.add_argument('--lr', type=float, default=0.1, metavar='LR',\n",
    "                    help='learning rate (default: 0.1)')\n",
    "parser.add_argument('--step', type=int, default=1, metavar='N',\n",
    "                    help='number of epochs between learning rate reductions (default: 1)')\n",
    "parser.add_argument('--gamma', type=float, default=0.9, metavar='M',\n",
    "                    help='Learning rate step gamma (default: 0.7)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=2, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "parser.add_argument('--evaluate', action='store_true', default=False,\n",
    "                    help='evaluate your model on the official test set')\n",
    "parser.add_argument('--load-model', type=str,\n",
    "                    help='model file path')\n",
    "parser.add_argument('--save-model', action='store_true', default=True,\n",
    "                    help='For Saving the current Model')\n",
    "parser.add_argument('--data-partition', type=int, default=1, metavar='N',\n",
    "                    help='Choose subset of  training set (default: 1)')\n",
    "parser.add_argument('--reg-lambda', type=float, default=0.0008, metavar='L',\n",
    "                    help='Regularization lambda (default:0.0008)')    \n",
    "args = parser.parse_args('--batch-size 128 --epochs 1 --log-interval 20 --lr 0.1'.split())\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "torch.manual_seed(args.seed)    \n",
    "\n",
    "partition = args.data_partition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_rs, w_rs = 60,160\n",
    "if os.environ['COMPUTERNAME']=='HOME-JIALIANG':\n",
    "    path_pos = r'D:\\Data\\Unity\\Minos\\pos0.bin'\n",
    "    dir_images = r'D:\\Data\\Unity\\Minos\\images0'\n",
    "else:\n",
    "    path_pos = '../../data/pos0.bin'\n",
    "    dir_images = '../../data/images0'\n",
    "\n",
    "rfd = '../../results_project/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize((h_rs,w_rs)),\n",
    "    transforms.Grayscale(),\n",
    "    # transforms.ColorJitter(brightness=0.05, contrast=0.05),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "full_dataset = EyeTrackingDataset(path_pos = path_pos, dir_images = dir_images, transform=img_transform)\n",
    "\n",
    "\n",
    "train_length= int(0.7 * len(full_dataset))\n",
    "val_length = int(0.1 * len(full_dataset))\n",
    "test_length = len(full_dataset) - train_length - val_length\n",
    "\n",
    "np.random.seed(1)\n",
    "train_dataset, val_dataset, test_dataset=torch.utils.data.random_split(full_dataset,(train_length,val_length,test_length))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=False, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=args.test_batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=args.test_batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "# Take a look at the data    \n",
    "img,target,target_fove = train_dataset[0]\n",
    "plt.imshow(img.numpy()[0].squeeze(),cmap = 'gray')\n",
    "plt.title(f'{target}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    " \n",
    "    def __init__(self, h_rs, w_rs, args):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "#         self.polar = args.polar\n",
    "        \n",
    "        self.act = nn.ELU()\n",
    "        # (1, 60, 160)\n",
    "        \n",
    "        self.d1 = 32\n",
    "        self.conv1 = nn.Conv2d(1, self.d1, kernel_size=3, stride=1, padding=1, padding_mode='replicate')\n",
    "        # (32, 60, 160)\n",
    "        self.batchNorm1 = nn.BatchNorm2d(self.d1)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.dropout2d1 = nn.Dropout2d(0.9)\n",
    "        # (32, 30, 80)\n",
    "        \n",
    "        self.d2 = 32\n",
    "        self.conv2 = nn.Conv2d(self.d1, self.d2, kernel_size=3, stride=1, padding=1, padding_mode='replicate')\n",
    "        # (32, 30, 80)\n",
    "        self.batchNorm2 = nn.BatchNorm2d(self.d2)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.dropout2d2 = nn.Dropout2d(0.9)\n",
    "        # (32, 15, 40)\n",
    "        \n",
    "        self.d3 = 64\n",
    "        self.conv3 = nn.Conv2d(self.d2, self.d3, kernel_size=3, stride=1, padding=1, padding_mode='replicate')\n",
    "        # (64, 15, 40)\n",
    "        self.batchNorm3 = nn.BatchNorm2d(self.d3)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.dropout2d3 = nn.Dropout2d(0.9)\n",
    "        # (64, 7, 20)\n",
    "        \n",
    "        self.d4 = 64\n",
    "        self.conv4 = nn.Conv2d(self.d3, self.d4, kernel_size=3, stride=1, padding=1, padding_mode='replicate')\n",
    "        # (64, 7, 20)\n",
    "        self.batchNorm4 = nn.BatchNorm2d(self.d4)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "        self.dropout2d4 = nn.Dropout2d(0.9)\n",
    "        # (64, 3, 10)\n",
    "        \n",
    "        self.fc1 = nn.Linear(1920, 16)\n",
    "        self.dropout1 = nn.Dropout(0.8)\n",
    "        self.fc2 = nn.Linear(16, 16)\n",
    "        self.dropout2 = nn.Dropout(0.8)\n",
    "        self.fc3 = nn.Linear(16, 3)\n",
    "        \n",
    "        self.forward_pass = nn.Sequential(\n",
    "            self.conv1, self.batchNorm1, self.act, self.pool1, #self.dropout2d1, \n",
    "            self.conv2, self.batchNorm2, self.act, self.pool2, #self.dropout2d2, \n",
    "            self.conv3, self.batchNorm3, self.act, self.pool3, #self.dropout2d3, \n",
    "            self.conv4, self.batchNorm4, self.act, self.pool4, #self.dropout2d4, \n",
    "            nn.Flatten(), \n",
    "            self.fc1, self.act, \n",
    "            self.fc2, self.act, \n",
    "            self.fc3\n",
    "        )\n",
    "        \n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=args.lr)\n",
    "        self.scheduler = StepLR(self.optimizer, step_size=args.step, gamma=args.gamma)\n",
    "\n",
    "#     def __init__(self,h_rs,w_rs,args):\n",
    "#         super(Net, self).__init__()        \n",
    "#         self.args = args\n",
    "        \n",
    "#         chns = [32, 32, 64, 64]\n",
    "#         self.kers = [3, 3, 3, 3]\n",
    "#         self.strides = [1, 1, 1, 1]\n",
    "\n",
    "#         lin_in_w = self.calculate_size(w_rs)\n",
    "#         lin_in_h = self.calculate_size(h_rs)\n",
    "\n",
    "#         self.conv1 = nn.Conv2d(1,       chns[0], self.kers[0], self.strides[0])\n",
    "#         self.conv2 = nn.Conv2d(chns[0], chns[1], self.kers[1], self.strides[1])\n",
    "#         self.conv3 = nn.Conv2d(chns[1], chns[2], self.kers[2], self.strides[2])\n",
    "#         self.conv4 = nn.Conv2d(chns[2], chns[3], self.kers[3], self.strides[3])\n",
    "        \n",
    "#         self.fc1 = nn.Linear(chns[-1]*lin_in_h*lin_in_w, 16)\n",
    "#         self.fc2 = nn.Linear(16, 16)       \n",
    "#         self.fc3 = nn.Linear(16, 3)\n",
    "        \n",
    "#         self.activate = nn.ELU()\n",
    "#         kdrop = 1\n",
    "        \n",
    "#         self.forward_pass = nn.Sequential(\n",
    "#             self.conv1, nn.BatchNorm2d(chns[0]), self.activate, nn.MaxPool2d(2), nn.Dropout2d(kdrop), \n",
    "#             self.conv2, nn.BatchNorm2d(chns[1]), self.activate, nn.MaxPool2d(2), nn.Dropout2d(kdrop), \n",
    "#             self.conv3, nn.BatchNorm2d(chns[2]), self.activate, nn.MaxPool2d(2), nn.Dropout2d(kdrop), \n",
    "#             self.conv4, nn.BatchNorm2d(chns[3]), self.activate, nn.MaxPool2d(2), nn.Dropout2d(kdrop), \n",
    "#             nn.Flatten(), self.fc1, self.activate,\n",
    "#             self.fc2, self.activate,\n",
    "#             self.fc3\n",
    "#         )\n",
    "        \n",
    "        self.criterion_train = nn.MSELoss()\n",
    "        self.criterion_test = nn.MSELoss(reduction='sum')\n",
    "        # Try different optimzers here [Adadelta, Adam, SGD, RMSprop]\n",
    "        self.optimizer = optim.Adadelta(self.parameters(), lr=args.lr)\n",
    "        # self.scheduler = ReduceLROnPlateau(self.optimizer, 'min')\n",
    "        self.scheduler = StepLR(self.optimizer, step_size=args.step, gamma=args.gamma)\n",
    "    \n",
    "    \n",
    "    def calculate_size(self, size_in):\n",
    "        # conv_out = (conv_in + 2×padding - kernel_size) / stride +1\n",
    "\n",
    "        size_out = np.floor((size_in  - self.kers[0] + 1) / 2)\n",
    "        size_out = np.floor((size_out - self.kers[1] + 1) / 2)\n",
    "        size_out = np.floor((size_out - self.kers[2] + 1) / 2)\n",
    "        size_out = np.floor(np.floor((size_out - self.kers[3]) / self.strides[3] +1) / 2)\n",
    "\n",
    "        return int(size_out)\n",
    "    \n",
    "    \n",
    "    def forward(self, x, target):\n",
    "       \n",
    "        output = self.forward_pass(x)\n",
    "        # for layer in self.forward_pass:\n",
    "        #     x = layer(x)\n",
    "        #     print(x.size())\n",
    "        # output = x\n",
    "        \n",
    "            \n",
    "        if self.training:  \n",
    "            loss = self.criterion_train(output, target)     \n",
    "\n",
    "            for param in self.parameters():    # Compute regularization\n",
    "                loss += self.args.reg_lambda*torch.mean(torch.abs(param))\n",
    "                \n",
    "            self.optimizer.zero_grad()               # Clear the gradient              \n",
    "            loss.backward()                     # Gradient computation\n",
    "            self.optimizer.step() \n",
    "        else:\n",
    "             loss = self.criterion_test(output, target)     \n",
    "\n",
    "        return output,loss\n",
    "\n",
    "        \n",
    "    def train_iterate(self, device, epoch, train_loader):      \n",
    "        start_time = time.time()           \n",
    "        for batch_idx, (data, target, target_fove) in enumerate(train_loader):\n",
    "            data, target = data.to(device,dtype=torch.float), target[:,:3].to(device,dtype=torch.float)           \n",
    "            output, loss = self.forward(data, target)                # Make predictions\n",
    "\n",
    "            if batch_idx % self.args.log_interval == 0:\n",
    "                print('\\nTrain Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.4f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.item()))\n",
    "                                \n",
    "                print('Examples:')\n",
    "                for i in range(3):\n",
    "                    print('True:', f'{target[i, :]}', \n",
    "                          'Pred:', f'{output[i, :]}')\n",
    "  \n",
    "                    # print('Train Max:', f'{data[i][0].max()}')\n",
    "\n",
    "                total_time = time.time() - start_time\n",
    "                print(f'Time per {self.args.log_interval} iters: {total_time:.2f}s')\n",
    "                                               \n",
    "                \n",
    "                # self.eval()\n",
    "                # data = data[:3]\n",
    "                # target = target[:3]\n",
    "                # output, loss = self.forward(data, target)                # Make predictions\n",
    "                \n",
    "                # print('\\nCheck Test: 3 loss: {:.4f}'.format(loss))\n",
    "                # print('Examples:')\n",
    "                # for i in range(3):\n",
    "                #     print('Data:', [f'{data[i][0].mean(axis=0)[d]}' for d in range(25,30)], \n",
    "                #           'Pred:', [f'{output.tolist()[i][d]:.3f}' for d in range(3)])\n",
    "                #     print('Test Max:', f'{data[i][0].max()}')\n",
    "                \n",
    "                # self.train()\n",
    "                \n",
    "        return loss\n",
    "           \n",
    "    def test_iterate(self, device, test_loader):     \n",
    "        \n",
    "        test_loss = 0   \n",
    "        preds = []\n",
    "        trues = [] \n",
    "        \n",
    "        for batch_idx, (data, target, target_fove) in enumerate(test_loader):\n",
    "            data, target = data.to(device,dtype=torch.float), target[:,:3].to(device,dtype=torch.float)           \n",
    "            output, loss = self.forward(data, target)                # Make predictions\n",
    "            test_loss += loss  # sum up batch loss                        \n",
    "        \n",
    "            if self.args.evaluate:\n",
    "              print(f'Test batch {batch_idx}')              \n",
    "              trues.append(target.detach().numpy())\n",
    "              preds.append(output.detach().numpy())\n",
    "            # if batch_idx == 0:\n",
    "            #       break\n",
    "                \n",
    "        test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "        print('\\nTest set: Average loss: {:.4f}'.format(test_loss))\n",
    "        print('Examples:')\n",
    "        for i in range(3):\n",
    "            print('True:', [f'{target.tolist()[i][d]:.3f}' for d in range(3)], \n",
    "                  'Pred:', [f'{output.tolist()[i][d]:.3f}' for d in range(3)])\n",
    "                \n",
    "        return test_loss, trues, preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 0 [0/44800 (0%)]\tLoss: 21.6559\n",
      "Examples:\n",
      "True: tensor([ 0.4412, -0.1074,  2.9654], device='cuda:0') Pred: tensor([-0.3060, -0.1755, -0.1401], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([0.9455, 0.1685, 7.7871], device='cuda:0') Pred: tensor([-0.3004, -0.1897, -0.0490], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 0.6293, -0.9653,  4.2305], device='cuda:0') Pred: tensor([-0.2716, -0.1543, -0.0964], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 2.30s\n",
      "\n",
      "Train Epoch: 0 [2560/44800 (6%)]\tLoss: 4.3876\n",
      "Examples:\n",
      "True: tensor([-0.8007,  0.8126,  6.5944], device='cuda:0') Pred: tensor([-0.2260,  0.0584,  6.4846], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 4.0172, -2.4171,  7.4107], device='cuda:0') Pred: tensor([ 0.3574, -0.4930,  7.0847], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-1.8589,  1.8128,  6.4177], device='cuda:0') Pred: tensor([-0.3378,  0.1456,  6.1701], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 3.78s\n",
      "\n",
      "Train Epoch: 0 [5120/44800 (11%)]\tLoss: 3.4291\n",
      "Examples:\n",
      "True: tensor([0.3865, 0.3923, 3.1835], device='cuda:0') Pred: tensor([ 0.6941, -0.2224,  7.1129], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-1.1727,  1.5241,  6.6506], device='cuda:0') Pred: tensor([-0.8546,  0.6064,  6.7224], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-3.6329,  2.7796,  9.5793], device='cuda:0') Pred: tensor([-0.6520,  0.5507,  6.7506], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 5.25s\n",
      "\n",
      "Train Epoch: 0 [7680/44800 (17%)]\tLoss: 2.5051\n",
      "Examples:\n",
      "True: tensor([-0.2769,  1.9719,  6.8711], device='cuda:0') Pred: tensor([-0.8020,  0.9548,  6.7990], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([1.6271, 0.4161, 6.2395], device='cuda:0') Pred: tensor([ 1.6971, -0.2383,  6.8998], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 0.0705, -0.7951,  5.2473], device='cuda:0') Pred: tensor([-0.0136, -0.8848,  6.2142], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 6.75s\n",
      "\n",
      "Train Epoch: 0 [10240/44800 (23%)]\tLoss: 2.5419\n",
      "Examples:\n",
      "True: tensor([-2.7892,  0.7133, 10.6962], device='cuda:0') Pred: tensor([-1.1478,  0.7513,  7.5152], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-1.1233, -0.4918,  2.7379], device='cuda:0') Pred: tensor([-2.2081, -1.7796,  4.9573], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-0.4389, -1.2689,  4.6564], device='cuda:0') Pred: tensor([-0.6895, -1.3796,  5.7501], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 8.22s\n",
      "\n",
      "Train Epoch: 0 [12800/44800 (29%)]\tLoss: 1.9540\n",
      "Examples:\n",
      "True: tensor([ 1.5757, -0.1487,  3.8405], device='cuda:0') Pred: tensor([ 2.3767, -0.5420,  6.2121], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 2.7176, -1.0641,  4.7071], device='cuda:0') Pred: tensor([ 2.9843, -1.1609,  6.5138], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 1.1799, -1.6268,  9.7174], device='cuda:0') Pred: tensor([ 0.8288, -1.2488,  7.0869], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 9.69s\n",
      "\n",
      "Train Epoch: 0 [15360/44800 (34%)]\tLoss: 2.0376\n",
      "Examples:\n",
      "True: tensor([1.2237, 0.2724, 3.2266], device='cuda:0') Pred: tensor([ 2.3923, -0.8957,  7.4331], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 2.3361, -1.9506,  8.9587], device='cuda:0') Pred: tensor([ 2.7701, -1.3537,  8.4345], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-3.2894,  0.6985, 10.3117], device='cuda:0') Pred: tensor([-2.6966,  0.5912,  9.0958], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 11.17s\n",
      "\n",
      "Train Epoch: 0 [17920/44800 (40%)]\tLoss: 1.7772\n",
      "Examples:\n",
      "True: tensor([ 0.7893,  0.2528, 11.7400], device='cuda:0') Pred: tensor([1.6566, 0.5103, 8.2536], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-1.3077,  0.1850,  3.4480], device='cuda:0') Pred: tensor([-2.4011,  0.1895,  4.4413], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-2.1857, -1.8160, 10.7062], device='cuda:0') Pred: tensor([ 0.2321, -1.4551,  5.9595], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 12.63s\n",
      "\n",
      "Train Epoch: 0 [20480/44800 (46%)]\tLoss: 1.0117\n",
      "Examples:\n",
      "True: tensor([ 1.8099, -0.7286,  5.6739], device='cuda:0') Pred: tensor([ 1.0859, -0.4590,  5.4679], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-0.8405, -0.2428,  4.7665], device='cuda:0') Pred: tensor([-1.3588,  0.2361,  5.1939], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-0.8268, -0.9390,  6.8091], device='cuda:0') Pred: tensor([-1.5259, -0.1686,  5.1686], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 14.12s\n",
      "\n",
      "Train Epoch: 0 [23040/44800 (51%)]\tLoss: 1.4368\n",
      "Examples:\n",
      "True: tensor([-4.8674,  2.0545, 10.2579], device='cuda:0') Pred: tensor([-2.5027,  1.9073,  9.3872], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-1.6310, -0.5185,  3.0088], device='cuda:0') Pred: tensor([-1.8597, -0.7298,  4.2602], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-3.1105, -1.6939, 10.7387], device='cuda:0') Pred: tensor([-0.7302, -0.7688,  8.4967], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 15.60s\n",
      "\n",
      "Train Epoch: 0 [25600/44800 (57%)]\tLoss: 1.3084\n",
      "Examples:\n",
      "True: tensor([-1.7233, -1.1350,  6.6084], device='cuda:0') Pred: tensor([-1.3403, -1.3849,  7.1281], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-2.3047,  0.3121,  4.2516], device='cuda:0') Pred: tensor([-2.7991,  0.2830,  6.4836], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 1.0038, -1.2722,  4.3215], device='cuda:0') Pred: tensor([ 1.1717, -1.4311,  6.8177], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 17.08s\n",
      "\n",
      "Train Epoch: 0 [28160/44800 (63%)]\tLoss: 0.9387\n",
      "Examples:\n",
      "True: tensor([ 0.7112,  0.5318, 10.5782], device='cuda:0') Pred: tensor([ 0.3044,  0.5144, 11.6793], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([1.8567, 0.8702, 4.8956], device='cuda:0') Pred: tensor([2.6905, 0.8449, 6.3843], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-0.1409, -1.5902, 10.4947], device='cuda:0') Pred: tensor([-0.6381, -1.3062, 11.4349], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 18.56s\n",
      "\n",
      "Train Epoch: 0 [30720/44800 (69%)]\tLoss: 0.9413\n",
      "Examples:\n",
      "True: tensor([-3.7088, -2.4807,  7.8161], device='cuda:0') Pred: tensor([-3.1337, -2.2147,  8.9825], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 3.9206, -1.2519,  8.2625], device='cuda:0') Pred: tensor([ 4.3354, -0.9302,  8.8120], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-2.2889, -1.1084,  5.1784], device='cuda:0') Pred: tensor([-2.6682, -1.2523,  6.5142], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 20.03s\n",
      "\n",
      "Train Epoch: 0 [33280/44800 (74%)]\tLoss: 0.7527\n",
      "Examples:\n",
      "True: tensor([ 2.3988, -0.4295, 11.7500], device='cuda:0') Pred: tensor([ 1.6000,  0.8909, 11.3676], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-1.7260,  1.5614,  8.4547], device='cuda:0') Pred: tensor([-1.8133,  1.9277,  7.8469], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([3.0232, 2.0529, 7.9715], device='cuda:0') Pred: tensor([2.3000, 1.3151, 6.4939], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 21.50s\n",
      "\n",
      "Train Epoch: 0 [35840/44800 (80%)]\tLoss: 0.8642\n",
      "Examples:\n",
      "True: tensor([-2.0872,  2.1175,  8.0041], device='cuda:0') Pred: tensor([-1.7244,  1.9318,  7.3561], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 0.7765, -0.5690,  5.2197], device='cuda:0') Pred: tensor([ 0.6375, -0.8181,  7.5260], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([1.6566, 0.6537, 8.1146], device='cuda:0') Pred: tensor([ 1.2248, -0.1141,  7.2686], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 22.98s\n",
      "\n",
      "Train Epoch: 0 [38400/44800 (86%)]\tLoss: 0.8335\n",
      "Examples:\n",
      "True: tensor([-1.8700, -0.4453,  3.6823], device='cuda:0') Pred: tensor([-2.0610, -0.7272,  4.8194], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-4.9692, -1.5023,  9.7851], device='cuda:0') Pred: tensor([-3.0757, -1.2317,  9.7659], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 0.1386, -1.1132, 10.3238], device='cuda:0') Pred: tensor([ 0.4258, -1.9743,  9.6661], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 24.45s\n",
      "\n",
      "Train Epoch: 0 [40960/44800 (91%)]\tLoss: 1.0283\n",
      "Examples:\n",
      "True: tensor([ 2.3779, -0.9311,  4.1187], device='cuda:0') Pred: tensor([ 2.1352, -1.4964,  6.1809], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 0.4983, -1.6765,  7.4118], device='cuda:0') Pred: tensor([-0.2659, -1.8418,  6.9620], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-2.0588, -1.4273,  6.4539], device='cuda:0') Pred: tensor([-2.9406, -1.7472,  7.2834], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 25.94s\n",
      "\n",
      "Train Epoch: 0 [43520/44800 (97%)]\tLoss: 0.5823\n",
      "Examples:\n",
      "True: tensor([1.6854, 1.5902, 5.2834], device='cuda:0') Pred: tensor([2.2739, 1.4776, 6.5267], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-2.0293, -0.7605,  4.5911], device='cuda:0') Pred: tensor([-2.6298, -1.1640,  5.5927], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 0.2961, -0.6864,  7.3467], device='cuda:0') Pred: tensor([-0.3648, -0.9686,  6.0070], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 27.40s\n",
      "\n",
      "Test set: Average loss: 2.6325\n",
      "Examples:\n",
      "True: ['-0.659', '-1.374', '6.990'] Pred: ['-1.726', '-1.417', '4.694']\n",
      "True: ['-1.193', '0.841', '6.767'] Pred: ['-0.835', '1.090', '4.980']\n",
      "True: ['0.731', '-1.972', '10.875'] Pred: ['0.338', '-1.589', '8.753']\n",
      "\n",
      "Train Epoch: 1 [0/44800 (0%)]\tLoss: 0.8321\n",
      "Examples:\n",
      "True: tensor([ 0.4412, -0.1074,  2.9654], device='cuda:0') Pred: tensor([ 0.9306, -0.6168,  2.6142], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([0.9455, 0.1685, 7.7871], device='cuda:0') Pred: tensor([0.6240, 0.0989, 4.9352], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 0.6293, -0.9653,  4.2305], device='cuda:0') Pred: tensor([ 0.3357, -1.4963,  5.3459], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 2.31s\n",
      "\n",
      "Train Epoch: 1 [2560/44800 (6%)]\tLoss: 0.8572\n",
      "Examples:\n",
      "True: tensor([-0.8007,  0.8126,  6.5944], device='cuda:0') Pred: tensor([-0.9083,  1.0122,  5.9448], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 4.0172, -2.4171,  7.4107], device='cuda:0') Pred: tensor([ 3.3687, -1.5130,  6.1939], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-1.8589,  1.8128,  6.4177], device='cuda:0') Pred: tensor([-1.1092,  1.6005,  5.5918], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 3.79s\n",
      "\n",
      "Train Epoch: 1 [5120/44800 (11%)]\tLoss: 0.9179\n",
      "Examples:\n",
      "True: tensor([0.3865, 0.3923, 3.1835], device='cuda:0') Pred: tensor([1.3821, 0.7478, 4.0982], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-1.1727,  1.5241,  6.6506], device='cuda:0') Pred: tensor([-1.3401,  1.9550,  6.9628], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-3.6329,  2.7796,  9.5793], device='cuda:0') Pred: tensor([-2.1151,  2.4908,  8.4658], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 5.27s\n",
      "\n",
      "Train Epoch: 1 [7680/44800 (17%)]\tLoss: 0.6490\n",
      "Examples:\n",
      "True: tensor([-0.2769,  1.9719,  6.8711], device='cuda:0') Pred: tensor([0.1342, 1.3607, 5.4738], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([1.6271, 0.4161, 6.2395], device='cuda:0') Pred: tensor([2.2004, 0.9023, 4.6263], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 0.0705, -0.7951,  5.2473], device='cuda:0') Pred: tensor([ 0.7375, -0.6499,  5.5661], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 6.75s\n",
      "\n",
      "Train Epoch: 1 [10240/44800 (23%)]\tLoss: 0.8286\n",
      "Examples:\n",
      "True: tensor([-2.7892,  0.7133, 10.6962], device='cuda:0') Pred: tensor([-2.0373,  0.6515, 10.0324], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-1.1233, -0.4918,  2.7379], device='cuda:0') Pred: tensor([-1.9711, -1.0832,  3.1796], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-0.4389, -1.2689,  4.6564], device='cuda:0') Pred: tensor([-0.4449, -1.4487,  5.2224], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 8.24s\n",
      "\n",
      "Train Epoch: 1 [12800/44800 (29%)]\tLoss: 0.5040\n",
      "Examples:\n",
      "True: tensor([ 1.5757, -0.1487,  3.8405], device='cuda:0') Pred: tensor([ 1.3414, -0.2453,  4.0459], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 2.7176, -1.0641,  4.7071], device='cuda:0') Pred: tensor([ 2.9457, -1.2899,  5.2692], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 1.1799, -1.6268,  9.7174], device='cuda:0') Pred: tensor([ 0.3355, -1.8197,  8.7765], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 9.71s\n",
      "\n",
      "Train Epoch: 1 [15360/44800 (34%)]\tLoss: 0.6098\n",
      "Examples:\n",
      "True: tensor([1.2237, 0.2724, 3.2266], device='cuda:0') Pred: tensor([ 1.2413, -0.1043,  4.5385], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 2.3361, -1.9506,  8.9587], device='cuda:0') Pred: tensor([ 1.9791, -1.8409,  9.0748], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-3.2894,  0.6985, 10.3117], device='cuda:0') Pred: tensor([-4.1776,  0.9000,  9.6486], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 11.19s\n",
      "\n",
      "Train Epoch: 1 [17920/44800 (40%)]\tLoss: 0.6321\n",
      "Examples:\n",
      "True: tensor([ 0.7893,  0.2528, 11.7400], device='cuda:0') Pred: tensor([ 1.1753,  0.3512, 11.7763], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-1.3077,  0.1850,  3.4480], device='cuda:0') Pred: tensor([-2.8303,  0.2775,  5.5604], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-2.1857, -1.8160, 10.7062], device='cuda:0') Pred: tensor([-0.2967, -1.9239,  8.3526], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 12.67s\n",
      "\n",
      "Train Epoch: 1 [20480/44800 (46%)]\tLoss: 0.7495\n",
      "Examples:\n",
      "True: tensor([ 1.8099, -0.7286,  5.6739], device='cuda:0') Pred: tensor([ 1.8759, -0.9839,  6.7239], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-0.8405, -0.2428,  4.7665], device='cuda:0') Pred: tensor([-0.7138, -0.5453,  5.9522], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-0.8268, -0.9390,  6.8091], device='cuda:0') Pred: tensor([-0.5805, -0.9506,  6.8190], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 14.14s\n",
      "\n",
      "Train Epoch: 1 [23040/44800 (51%)]\tLoss: 0.4823\n",
      "Examples:\n",
      "True: tensor([-4.8674,  2.0545, 10.2579], device='cuda:0') Pred: tensor([-4.1965,  2.2128, 10.5669], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-1.6310, -0.5185,  3.0088], device='cuda:0') Pred: tensor([-2.0332, -0.8892,  4.1593], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-3.1105, -1.6939, 10.7387], device='cuda:0') Pred: tensor([-2.2150, -1.5860, 11.3789], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 15.61s\n",
      "\n",
      "Train Epoch: 1 [25600/44800 (57%)]\tLoss: 0.6069\n",
      "Examples:\n",
      "True: tensor([-1.7233, -1.1350,  6.6084], device='cuda:0') Pred: tensor([-0.9486, -1.1713,  6.4925], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-2.3047,  0.3121,  4.2516], device='cuda:0') Pred: tensor([-2.4009,  0.3319,  5.5716], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 1.0038, -1.2722,  4.3215], device='cuda:0') Pred: tensor([ 1.5642, -1.4072,  6.1282], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 17.09s\n",
      "\n",
      "Train Epoch: 1 [28160/44800 (63%)]\tLoss: 0.5017\n",
      "Examples:\n",
      "True: tensor([ 0.7112,  0.5318, 10.5782], device='cuda:0') Pred: tensor([-0.2541,  0.1531, 11.3702], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([1.8567, 0.8702, 4.8956], device='cuda:0') Pred: tensor([2.4853, 1.1517, 6.3254], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-0.1409, -1.5902, 10.4947], device='cuda:0') Pred: tensor([-1.1359, -1.8281, 11.6242], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 18.56s\n",
      "\n",
      "Train Epoch: 1 [30720/44800 (69%)]\tLoss: 0.6826\n",
      "Examples:\n",
      "True: tensor([-3.7088, -2.4807,  7.8161], device='cuda:0') Pred: tensor([-3.6563, -2.3650,  9.0988], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 3.9206, -1.2519,  8.2625], device='cuda:0') Pred: tensor([ 4.1832, -1.1461,  8.8357], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-2.2889, -1.1084,  5.1784], device='cuda:0') Pred: tensor([-2.8439, -1.2640,  6.7378], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 20.06s\n",
      "\n",
      "Train Epoch: 1 [33280/44800 (74%)]\tLoss: 0.4771\n",
      "Examples:\n",
      "True: tensor([ 2.3988, -0.4295, 11.7500], device='cuda:0') Pred: tensor([ 2.0327,  0.4150, 11.9430], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-1.7260,  1.5614,  8.4547], device='cuda:0') Pred: tensor([-1.6788,  1.9808,  8.2454], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([3.0232, 2.0529, 7.9715], device='cuda:0') Pred: tensor([2.9617, 1.6419, 7.2305], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 21.53s\n",
      "\n",
      "Train Epoch: 1 [35840/44800 (80%)]\tLoss: 0.6355\n",
      "Examples:\n",
      "True: tensor([-2.0872,  2.1175,  8.0041], device='cuda:0') Pred: tensor([-1.1387,  2.3452,  8.0190], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 0.7765, -0.5690,  5.2197], device='cuda:0') Pred: tensor([ 0.7092, -0.3374,  7.3764], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([1.6566, 0.6537, 8.1146], device='cuda:0') Pred: tensor([1.3969, 0.2747, 7.7344], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 23.00s\n",
      "\n",
      "Train Epoch: 1 [38400/44800 (86%)]\tLoss: 0.5313\n",
      "Examples:\n",
      "True: tensor([-1.8700, -0.4453,  3.6823], device='cuda:0') Pred: tensor([-2.0135, -0.6090,  4.7366], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-4.9692, -1.5023,  9.7851], device='cuda:0') Pred: tensor([-3.6414, -1.3858,  9.7220], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 0.1386, -1.1132, 10.3238], device='cuda:0') Pred: tensor([ 0.0411, -1.9520,  9.7005], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 24.50s\n",
      "\n",
      "Train Epoch: 1 [40960/44800 (91%)]\tLoss: 0.6792\n",
      "Examples:\n",
      "True: tensor([ 2.3779, -0.9311,  4.1187], device='cuda:0') Pred: tensor([ 1.9284, -1.2077,  5.5512], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 0.4983, -1.6765,  7.4118], device='cuda:0') Pred: tensor([-0.2704, -1.6198,  7.0929], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-2.0588, -1.4273,  6.4539], device='cuda:0') Pred: tensor([-2.7572, -1.6154,  6.9369], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 25.99s\n",
      "\n",
      "Train Epoch: 1 [43520/44800 (97%)]\tLoss: 0.4084\n",
      "Examples:\n",
      "True: tensor([1.6854, 1.5902, 5.2834], device='cuda:0') Pred: tensor([3.1912, 1.6093, 7.4111], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-2.0293, -0.7605,  4.5911], device='cuda:0') Pred: tensor([-2.4008, -1.0089,  5.6471], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 0.2961, -0.6864,  7.3467], device='cuda:0') Pred: tensor([ 0.4156, -0.7274,  6.7693], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 27.49s\n",
      "\n",
      "Test set: Average loss: 2.3761\n",
      "Examples:\n",
      "True: ['-0.659', '-1.374', '6.990'] Pred: ['-1.406', '-1.305', '4.669']\n",
      "True: ['-1.193', '0.841', '6.767'] Pred: ['-0.518', '0.883', '4.660']\n",
      "True: ['0.731', '-1.972', '10.875'] Pred: ['0.502', '-1.845', '9.146']\n",
      "\n",
      "Train Epoch: 2 [0/44800 (0%)]\tLoss: 0.6796\n",
      "Examples:\n",
      "True: tensor([ 0.4412, -0.1074,  2.9654], device='cuda:0') Pred: tensor([ 0.7308, -0.4409,  1.7362], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([0.9455, 0.1685, 7.7871], device='cuda:0') Pred: tensor([0.9181, 0.1060, 6.0558], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 0.6293, -0.9653,  4.2305], device='cuda:0') Pred: tensor([ 0.7375, -1.1846,  4.8233], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 2.26s\n",
      "\n",
      "Train Epoch: 2 [2560/44800 (6%)]\tLoss: 0.5931\n",
      "Examples:\n",
      "True: tensor([-0.8007,  0.8126,  6.5944], device='cuda:0') Pred: tensor([-1.1631,  0.6637,  5.8917], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 4.0172, -2.4171,  7.4107], device='cuda:0') Pred: tensor([ 2.9471, -1.7679,  6.5620], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-1.8589,  1.8128,  6.4177], device='cuda:0') Pred: tensor([-1.3789,  1.4335,  5.5766], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 3.73s\n",
      "\n",
      "Train Epoch: 2 [5120/44800 (11%)]\tLoss: 0.4551\n",
      "Examples:\n",
      "True: tensor([0.3865, 0.3923, 3.1835], device='cuda:0') Pred: tensor([0.7334, 0.4316, 3.1472], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-1.1727,  1.5241,  6.6506], device='cuda:0') Pred: tensor([-1.5110,  1.8681,  7.1845], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-3.6329,  2.7796,  9.5793], device='cuda:0') Pred: tensor([-2.9189,  2.6307,  9.1091], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 5.21s\n",
      "\n",
      "Train Epoch: 2 [7680/44800 (17%)]\tLoss: 0.5043\n",
      "Examples:\n",
      "True: tensor([-0.2769,  1.9719,  6.8711], device='cuda:0') Pred: tensor([0.1233, 1.4226, 5.6999], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([1.6271, 0.4161, 6.2395], device='cuda:0') Pred: tensor([2.0077, 0.6391, 4.7442], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 0.0705, -0.7951,  5.2473], device='cuda:0') Pred: tensor([ 0.5499, -0.4992,  5.6840], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 6.67s\n",
      "\n",
      "Train Epoch: 2 [10240/44800 (23%)]\tLoss: 0.6043\n",
      "Examples:\n",
      "True: tensor([-2.7892,  0.7133, 10.6962], device='cuda:0') Pred: tensor([-2.2371,  0.6751, 10.1933], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-1.1233, -0.4918,  2.7379], device='cuda:0') Pred: tensor([-1.5810, -0.8395,  2.1727], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-0.4389, -1.2689,  4.6564], device='cuda:0') Pred: tensor([-0.4609, -1.3006,  4.9987], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 8.15s\n",
      "\n",
      "Train Epoch: 2 [12800/44800 (29%)]\tLoss: 0.3840\n",
      "Examples:\n",
      "True: tensor([ 1.5757, -0.1487,  3.8405], device='cuda:0') Pred: tensor([ 1.5270, -0.0467,  3.7186], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 2.7176, -1.0641,  4.7071], device='cuda:0') Pred: tensor([ 2.8347, -1.0426,  4.8926], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 1.1799, -1.6268,  9.7174], device='cuda:0') Pred: tensor([ 0.6704, -1.5373,  8.6691], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 9.63s\n",
      "\n",
      "Train Epoch: 2 [15360/44800 (34%)]\tLoss: 0.3806\n",
      "Examples:\n",
      "True: tensor([1.2237, 0.2724, 3.2266], device='cuda:0') Pred: tensor([ 1.0349, -0.1461,  3.1479], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 2.3361, -1.9506,  8.9587], device='cuda:0') Pred: tensor([ 1.9552, -2.1131,  8.9644], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-3.2894,  0.6985, 10.3117], device='cuda:0') Pred: tensor([-4.3805,  0.6007,  9.5612], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 11.10s\n",
      "\n",
      "Train Epoch: 2 [17920/44800 (40%)]\tLoss: 0.4293\n",
      "Examples:\n",
      "True: tensor([ 0.7893,  0.2528, 11.7400], device='cuda:0') Pred: tensor([ 0.7844,  0.0183, 11.3013], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-1.3077,  0.1850,  3.4480], device='cuda:0') Pred: tensor([-2.3449,  0.1458,  4.4813], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-2.1857, -1.8160, 10.7062], device='cuda:0') Pred: tensor([-0.4193, -1.8224,  8.6047], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 12.58s\n",
      "\n",
      "Train Epoch: 2 [20480/44800 (46%)]\tLoss: 0.4219\n",
      "Examples:\n",
      "True: tensor([ 1.8099, -0.7286,  5.6739], device='cuda:0') Pred: tensor([ 1.3994, -0.6416,  5.0421], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-0.8405, -0.2428,  4.7665], device='cuda:0') Pred: tensor([-0.6915, -0.2043,  4.4311], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-0.8268, -0.9390,  6.8091], device='cuda:0') Pred: tensor([-0.7653, -0.5634,  5.2562], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 14.04s\n",
      "\n",
      "Train Epoch: 2 [23040/44800 (51%)]\tLoss: 0.4292\n",
      "Examples:\n",
      "True: tensor([-4.8674,  2.0545, 10.2579], device='cuda:0') Pred: tensor([-3.6767,  2.2444,  9.9259], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-1.6310, -0.5185,  3.0088], device='cuda:0') Pred: tensor([-1.4311, -0.6360,  2.9124], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-3.1105, -1.6939, 10.7387], device='cuda:0') Pred: tensor([-2.0214, -1.4862, 10.4909], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 15.52s\n",
      "\n",
      "Train Epoch: 2 [25600/44800 (57%)]\tLoss: 0.4932\n",
      "Examples:\n",
      "True: tensor([-1.7233, -1.1350,  6.6084], device='cuda:0') Pred: tensor([-1.0039, -1.0941,  6.6118], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-2.3047,  0.3121,  4.2516], device='cuda:0') Pred: tensor([-2.2704,  0.3344,  5.3313], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 1.0038, -1.2722,  4.3215], device='cuda:0') Pred: tensor([ 1.3142, -1.3738,  6.1397], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 17.02s\n",
      "\n",
      "Train Epoch: 2 [28160/44800 (63%)]\tLoss: 0.4463\n",
      "Examples:\n",
      "True: tensor([ 0.7112,  0.5318, 10.5782], device='cuda:0') Pred: tensor([-7.4743e-03,  1.5045e-01,  1.1258e+01], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "True: tensor([1.8567, 0.8702, 4.8956], device='cuda:0') Pred: tensor([2.6610, 1.1392, 6.5472], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-0.1409, -1.5902, 10.4947], device='cuda:0') Pred: tensor([-0.8502, -1.8305, 11.5414], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 18.50s\n",
      "\n",
      "Train Epoch: 2 [30720/44800 (69%)]\tLoss: 0.5143\n",
      "Examples:\n",
      "True: tensor([-3.7088, -2.4807,  7.8161], device='cuda:0') Pred: tensor([-3.7035, -2.4055,  9.0250], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 3.9206, -1.2519,  8.2625], device='cuda:0') Pred: tensor([ 4.1521, -1.1180,  8.7339], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-2.2889, -1.1084,  5.1784], device='cuda:0') Pred: tensor([-2.7245, -1.1274,  6.4219], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 19.99s\n",
      "\n",
      "Train Epoch: 2 [33280/44800 (74%)]\tLoss: 0.3257\n",
      "Examples:\n",
      "True: tensor([ 2.3988, -0.4295, 11.7500], device='cuda:0') Pred: tensor([ 1.7362, -0.1487, 12.1750], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-1.7260,  1.5614,  8.4547], device='cuda:0') Pred: tensor([-1.8057,  1.7455,  8.2973], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([3.0232, 2.0529, 7.9715], device='cuda:0') Pred: tensor([2.9837, 1.8123, 7.4479], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 21.47s\n",
      "\n",
      "Train Epoch: 2 [35840/44800 (80%)]\tLoss: 0.4180\n",
      "Examples:\n",
      "True: tensor([-2.0872,  2.1175,  8.0041], device='cuda:0') Pred: tensor([-0.9811,  2.2892,  7.5490], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 0.7765, -0.5690,  5.2197], device='cuda:0') Pred: tensor([0.7990, 0.0178, 6.5023], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([1.6566, 0.6537, 8.1146], device='cuda:0') Pred: tensor([1.6246, 0.5847, 7.2325], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 22.95s\n",
      "\n",
      "Train Epoch: 2 [38400/44800 (86%)]\tLoss: 0.3689\n",
      "Examples:\n",
      "True: tensor([-1.8700, -0.4453,  3.6823], device='cuda:0') Pred: tensor([-2.1357, -0.5283,  5.1462], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-4.9692, -1.5023,  9.7851], device='cuda:0') Pred: tensor([-3.6526, -1.3087, 10.2168], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 0.1386, -1.1132, 10.3238], device='cuda:0') Pred: tensor([ 0.3741, -1.7792, 10.3550], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 24.43s\n",
      "\n",
      "Train Epoch: 2 [40960/44800 (91%)]\tLoss: 0.4135\n",
      "Examples:\n",
      "True: tensor([ 2.3779, -0.9311,  4.1187], device='cuda:0') Pred: tensor([ 1.8353, -1.0840,  4.9668], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 0.4983, -1.6765,  7.4118], device='cuda:0') Pred: tensor([-0.1993, -1.6132,  7.5787], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-2.0588, -1.4273,  6.4539], device='cuda:0') Pred: tensor([-2.5500, -1.4320,  6.8289], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 25.90s\n",
      "\n",
      "Train Epoch: 2 [43520/44800 (97%)]\tLoss: 0.3194\n",
      "Examples:\n",
      "True: tensor([1.6854, 1.5902, 5.2834], device='cuda:0') Pred: tensor([2.7976, 1.7122, 6.9554], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-2.0293, -0.7605,  4.5911], device='cuda:0') Pred: tensor([-2.5167, -1.1935,  5.3894], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 0.2961, -0.6864,  7.3467], device='cuda:0') Pred: tensor([-0.0763, -0.8590,  6.8792], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 27.37s\n",
      "\n",
      "Test set: Average loss: 1.0908\n",
      "Examples:\n",
      "True: ['-0.659', '-1.374', '6.990'] Pred: ['-1.559', '-1.268', '5.575']\n",
      "True: ['-1.193', '0.841', '6.767'] Pred: ['-0.663', '0.876', '5.026']\n",
      "True: ['0.731', '-1.972', '10.875'] Pred: ['0.270', '-1.905', '9.981']\n",
      "\n",
      "Train Epoch: 3 [0/44800 (0%)]\tLoss: 0.3704\n",
      "Examples:\n",
      "True: tensor([ 0.4412, -0.1074,  2.9654], device='cuda:0') Pred: tensor([ 0.4244, -0.3130,  1.9729], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([0.9455, 0.1685, 7.7871], device='cuda:0') Pred: tensor([0.7440, 0.0629, 7.1694], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 0.6293, -0.9653,  4.2305], device='cuda:0') Pred: tensor([ 0.5703, -1.1990,  4.9867], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 2.29s\n",
      "\n",
      "Train Epoch: 3 [2560/44800 (6%)]\tLoss: 0.4460\n",
      "Examples:\n",
      "True: tensor([-0.8007,  0.8126,  6.5944], device='cuda:0') Pred: tensor([-1.1209,  0.6384,  5.9231], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 4.0172, -2.4171,  7.4107], device='cuda:0') Pred: tensor([ 3.2146, -1.8224,  6.3732], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-1.8589,  1.8128,  6.4177], device='cuda:0') Pred: tensor([-1.3658,  1.5016,  5.6467], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 3.76s\n",
      "\n",
      "Train Epoch: 3 [5120/44800 (11%)]\tLoss: 0.4001\n",
      "Examples:\n",
      "True: tensor([0.3865, 0.3923, 3.1835], device='cuda:0') Pred: tensor([0.7082, 0.4306, 2.8955], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-1.1727,  1.5241,  6.6506], device='cuda:0') Pred: tensor([-1.3542,  1.8666,  7.0667], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-3.6329,  2.7796,  9.5793], device='cuda:0') Pred: tensor([-3.0202,  2.7394,  9.3492], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 5.26s\n",
      "\n",
      "Train Epoch: 3 [7680/44800 (17%)]\tLoss: 0.4227\n",
      "Examples:\n",
      "True: tensor([-0.2769,  1.9719,  6.8711], device='cuda:0') Pred: tensor([-0.1708,  1.4736,  5.9087], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([1.6271, 0.4161, 6.2395], device='cuda:0') Pred: tensor([1.7228, 0.4502, 4.7581], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 0.0705, -0.7951,  5.2473], device='cuda:0') Pred: tensor([ 0.3010, -0.5844,  5.6149], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 6.74s\n",
      "\n",
      "Train Epoch: 3 [10240/44800 (23%)]\tLoss: 0.4873\n",
      "Examples:\n",
      "True: tensor([-2.7892,  0.7133, 10.6962], device='cuda:0') Pred: tensor([-2.2548,  0.5388, 10.3307], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-1.1233, -0.4918,  2.7379], device='cuda:0') Pred: tensor([-1.6162, -0.7679,  2.1604], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-0.4389, -1.2689,  4.6564], device='cuda:0') Pred: tensor([-0.6604, -1.3535,  4.6907], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 8.21s\n",
      "\n",
      "Train Epoch: 3 [12800/44800 (29%)]\tLoss: 0.3041\n",
      "Examples:\n",
      "True: tensor([ 1.5757, -0.1487,  3.8405], device='cuda:0') Pred: tensor([ 1.3786, -0.0858,  3.6551], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 2.7176, -1.0641,  4.7071], device='cuda:0') Pred: tensor([ 2.5713, -1.0230,  4.8714], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 1.1799, -1.6268,  9.7174], device='cuda:0') Pred: tensor([ 0.6420, -1.5405,  8.7737], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 9.69s\n",
      "\n",
      "Train Epoch: 3 [15360/44800 (34%)]\tLoss: 0.3078\n",
      "Examples:\n",
      "True: tensor([1.2237, 0.2724, 3.2266], device='cuda:0') Pred: tensor([ 1.0182, -0.0738,  2.6882], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 2.3361, -1.9506,  8.9587], device='cuda:0') Pred: tensor([ 2.0710, -2.1711,  8.9407], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-3.2894,  0.6985, 10.3117], device='cuda:0') Pred: tensor([-4.4639,  0.5005,  9.6925], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 11.16s\n",
      "\n",
      "Train Epoch: 3 [17920/44800 (40%)]\tLoss: 0.4225\n",
      "Examples:\n",
      "True: tensor([ 0.7893,  0.2528, 11.7400], device='cuda:0') Pred: tensor([ 0.9738,  0.1056, 11.8331], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-1.3077,  0.1850,  3.4480], device='cuda:0') Pred: tensor([-2.5765,  0.2961,  5.1349], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-2.1857, -1.8160, 10.7062], device='cuda:0') Pred: tensor([-0.4779, -1.7126,  9.0967], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 12.66s\n",
      "\n",
      "Train Epoch: 3 [20480/44800 (46%)]\tLoss: 0.4771\n",
      "Examples:\n",
      "True: tensor([ 1.8099, -0.7286,  5.6739], device='cuda:0') Pred: tensor([ 1.4581, -1.0015,  6.6874], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-0.8405, -0.2428,  4.7665], device='cuda:0') Pred: tensor([-0.8611, -0.4532,  5.5250], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-0.8268, -0.9390,  6.8091], device='cuda:0') Pred: tensor([-0.8285, -1.0139,  7.1526], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 14.14s\n",
      "\n",
      "Train Epoch: 3 [23040/44800 (51%)]\tLoss: 0.2793\n",
      "Examples:\n",
      "True: tensor([-4.8674,  2.0545, 10.2579], device='cuda:0') Pred: tensor([-3.9471,  2.4102, 10.3306], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-1.6310, -0.5185,  3.0088], device='cuda:0') Pred: tensor([-1.5318, -0.5368,  3.5218], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-3.1105, -1.6939, 10.7387], device='cuda:0') Pred: tensor([-2.4354, -1.5587, 11.0801], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 15.61s\n",
      "\n",
      "Train Epoch: 3 [25600/44800 (57%)]\tLoss: 0.3905\n",
      "Examples:\n",
      "True: tensor([-1.7233, -1.1350,  6.6084], device='cuda:0') Pred: tensor([-1.0042, -1.0986,  6.5417], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-2.3047,  0.3121,  4.2516], device='cuda:0') Pred: tensor([-2.2148,  0.3142,  5.0552], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 1.0038, -1.2722,  4.3215], device='cuda:0') Pred: tensor([ 1.2811, -1.5306,  6.0126], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 17.08s\n",
      "\n",
      "Train Epoch: 3 [28160/44800 (63%)]\tLoss: 0.3560\n",
      "Examples:\n",
      "True: tensor([ 0.7112,  0.5318, 10.5782], device='cuda:0') Pred: tensor([-0.2169,  0.1269, 11.0773], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([1.8567, 0.8702, 4.8956], device='cuda:0') Pred: tensor([2.4269, 1.0653, 6.3645], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-0.1409, -1.5902, 10.4947], device='cuda:0') Pred: tensor([-1.1009, -1.8290, 11.3356], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 18.55s\n",
      "\n",
      "Train Epoch: 3 [30720/44800 (69%)]\tLoss: 0.4777\n",
      "Examples:\n",
      "True: tensor([-3.7088, -2.4807,  7.8161], device='cuda:0') Pred: tensor([-3.7481, -2.5767,  9.0036], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 3.9206, -1.2519,  8.2625], device='cuda:0') Pred: tensor([ 4.1713, -1.2574,  8.7679], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-2.2889, -1.1084,  5.1784], device='cuda:0') Pred: tensor([-2.7243, -1.1811,  6.2140], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 20.03s\n",
      "\n",
      "Train Epoch: 3 [33280/44800 (74%)]\tLoss: 0.2470\n",
      "Examples:\n",
      "True: tensor([ 2.3988, -0.4295, 11.7500], device='cuda:0') Pred: tensor([ 1.9403, -0.2040, 12.1651], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-1.7260,  1.5614,  8.4547], device='cuda:0') Pred: tensor([-1.7463,  1.7785,  8.2656], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([3.0232, 2.0529, 7.9715], device='cuda:0') Pred: tensor([3.0794, 1.9771, 7.4733], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 21.52s\n",
      "\n",
      "Train Epoch: 3 [35840/44800 (80%)]\tLoss: 0.4540\n",
      "Examples:\n",
      "True: tensor([-2.0872,  2.1175,  8.0041], device='cuda:0') Pred: tensor([-1.2187,  1.9130,  6.9232], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 0.7765, -0.5690,  5.2197], device='cuda:0') Pred: tensor([ 0.3506, -0.1791,  5.1539], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([1.6566, 0.6537, 8.1146], device='cuda:0') Pred: tensor([1.3583, 0.4695, 6.3129], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 22.99s\n",
      "\n",
      "Train Epoch: 3 [38400/44800 (86%)]\tLoss: 0.4311\n",
      "Examples:\n",
      "True: tensor([-1.8700, -0.4453,  3.6823], device='cuda:0') Pred: tensor([-1.6087, -0.3407,  3.5639], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-4.9692, -1.5023,  9.7851], device='cuda:0') Pred: tensor([-3.5063, -1.2588,  9.3852], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 0.1386, -1.1132, 10.3238], device='cuda:0') Pred: tensor([ 0.3164, -1.5889,  9.5608], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 24.46s\n",
      "\n",
      "Train Epoch: 3 [40960/44800 (91%)]\tLoss: 0.4015\n",
      "Examples:\n",
      "True: tensor([ 2.3779, -0.9311,  4.1187], device='cuda:0') Pred: tensor([ 1.7181, -1.0883,  4.7933], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 0.4983, -1.6765,  7.4118], device='cuda:0') Pred: tensor([-0.3298, -1.6920,  7.9048], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-2.0588, -1.4273,  6.4539], device='cuda:0') Pred: tensor([-2.6796, -1.5675,  7.2793], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 25.93s\n",
      "\n",
      "Train Epoch: 3 [43520/44800 (97%)]\tLoss: 0.3957\n",
      "Examples:\n",
      "True: tensor([1.6854, 1.5902, 5.2834], device='cuda:0') Pred: tensor([3.1559, 1.8744, 7.2443], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([-2.0293, -0.7605,  4.5911], device='cuda:0') Pred: tensor([-2.3587, -1.0161,  5.6076], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "True: tensor([ 0.2961, -0.6864,  7.3467], device='cuda:0') Pred: tensor([ 0.2611, -0.7758,  7.6108], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Time per 20 iters: 27.40s\n",
      "\n",
      "Test set: Average loss: 0.9326\n",
      "Examples:\n",
      "True: ['-0.659', '-1.374', '6.990'] Pred: ['-1.416', '-1.320', '5.753']\n",
      "True: ['-1.193', '0.841', '6.767'] Pred: ['-0.608', '0.811', '4.887']\n",
      "True: ['0.731', '-1.972', '10.875'] Pred: ['0.257', '-1.934', '9.994']\n"
     ]
    }
   ],
   "source": [
    "model = Net(h_rs,w_rs,args).to(device)\n",
    "\n",
    "train_batch_losses, val_losses = [],[]\n",
    "\n",
    "# Training loop   \n",
    "for epoch in range(4):\n",
    "    model.train()\n",
    "    train_batch_loss = model.train_iterate(device,epoch,train_loader)\n",
    "\n",
    "    model.eval()                       \n",
    "    with torch.no_grad():\n",
    "        val_loss, _ , _ = model.test_iterate(device,val_loader)\n",
    "\n",
    "    # remember best loss and save   \n",
    "    val_loss = val_loss.cpu().numpy()             \n",
    "#     if args.save_model and val_loss < best_loss:            \n",
    "#         best_loss = val_loss           \n",
    "#         torch.save(model.state_dict(), 'eye_tracking_model.pt')\n",
    "#         np.save(rfd + 'best_loss.npy', best_loss)\n",
    "#         best_loss = val_loss\n",
    "\n",
    "    # record train & val loss for every epoch \n",
    "    train_batch_losses.append(train_batch_loss.item())\n",
    "    val_losses.append(val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6764171719551086"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
