{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rc('image', cmap='gray')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from EyeTracking import EyeTrackingDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                    help='input batch size for training (default: 64)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                    help='input batch size for testing (default: 1000)')\n",
    "parser.add_argument('--validation-percentage', type=float, default=15., metavar='P',\n",
    "                   help='percentage of training data used for validation')\n",
    "# parser.add_argument('--training-division', type=float, default=1., metavar='D',\n",
    "#                    help='divide the remaining training data by this factor')\n",
    "parser.add_argument('--epochs', type=int, default=14, metavar='N',\n",
    "                    help='number of epochs to train (default: 14)')\n",
    "parser.add_argument('--lr', type=float, default=1.0, metavar='LR',\n",
    "                    help='learning rate (default: 1.0)')\n",
    "parser.add_argument('--step', type=int, default=1, metavar='N',\n",
    "                    help='number of epochs between learning rate reductions (default: 1)')\n",
    "parser.add_argument('--gamma', type=float, default=0.7, metavar='M',\n",
    "                    help='Learning rate step gamma (default: 0.7)')\n",
    "parser.add_argument('--reg-lambda', type=float, default=0.001, metavar='L',\n",
    "                    help='Regularization lambda (default:0.001)')\n",
    "parser.add_argument('--no-cuda', action='store_true',\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-numbers', type=int, default=10, metavar='N',\n",
    "                    help='how many entries of logging training status to show per epoch')\n",
    "parser.add_argument('--evaluate', action='store_true',\n",
    "                    help='evaluate your model on the official test set')\n",
    "parser.add_argument('--load-model', type=str,\n",
    "                    help='model file path')\n",
    "parser.add_argument('--save-model', type=str,\n",
    "                    help='For Saving the current Model');\n",
    "\n",
    "args = parser.parse_args('--validation-percentage 10 --batch-size 128 --epochs 8 --lr 1 --step 1 --gamma 0.9 --reg-lambda 0.0008 --seed 2020 --log-numbers 20'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(args.seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "path_outputs = '../data/project'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_images = r'E:\\Data\\Unity\\Minos\\Fixation Training Images'\n",
    "path_pos = r'E:\\Data\\Unity\\Minos\\Fixation Training Pos.bin'\n",
    "dataset = EyeTrackingDataset(path_pos, dir_images, transform=transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize(60),\n",
    "    transforms.ColorJitter(brightness=0.05, contrast=0.05),\n",
    "    transforms.ToTensor()\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 64000 samples and divided into 57600 training and 6400 validation samples\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(args.seed)\n",
    "idc = rng.permutation(len(dataset))\n",
    "n_train = np.round(len(dataset)*(1-args.validation_percentage/100)).astype(int)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset, batch_size=args.batch_size,\n",
    "    sampler=SubsetRandomSampler(idc[:n_train]), **kwargs\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset, batch_size=args.batch_size,\n",
    "    sampler=SubsetRandomSampler(idc[n_train:]), **kwargs\n",
    ")\n",
    "\n",
    "print(f'Loaded {len(dataset)} samples and divided into {len(train_loader.sampler)} training and {len(val_loader.sampler)} validation samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.7675695  3.3076482  9.989724 ]\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(dataset[0][0].numpy().squeeze())\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "print(dataset[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch, reg_lambda=0.001, verbose=True):\n",
    "    '''\n",
    "    This is your training function. When you call this function, the model is\n",
    "    trained for 1 epoch.\n",
    "    '''\n",
    "    model.train()   # Set the model to training mode\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()               # Clear the gradient\n",
    "        output = model(data)                # Make predictions\n",
    "        loss = F.mse_loss(output, target)   # Compute loss\n",
    "        for param in model.parameters():    # Compute regularization\n",
    "            loss += reg_lambda*torch.mean(torch.abs(param))\n",
    "        loss.backward()                     # Gradient computation\n",
    "        optimizer.step()                    # Perform a single optimization step\n",
    "        if batch_idx % args.log_numbers == 0 and verbose:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch+1, batch_idx * len(data), len(train_loader.sampler),\n",
    "                100. * batch_idx * len(data) / len(train_loader.sampler), loss.item()))\n",
    "\n",
    "def test(model, device, test_loader, name='Validation', verbose=True):\n",
    "    model.eval()    # Set the model to inference mode\n",
    "    test_loss = 0.\n",
    "    with torch.no_grad():   # For the inference step, gradient is not computed\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.mse_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "\n",
    "    test_loss /= len(test_loader.sampler)\n",
    "    \n",
    "    if verbose:\n",
    "        print('{:s} set: Average loss: {:.4f}'.format(\n",
    "            name, test_loss))\n",
    "    \n",
    "    return test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.act = nn.ELU()\n",
    "        # (1, 60, 160)\n",
    "        \n",
    "        self.d1 = 16\n",
    "        self.conv1 = nn.Conv2d(1, self.d1, kernel_size=3, stride=1, padding=1, padding_mode='replicate')\n",
    "        # (16, 60, 160)\n",
    "        self.batchNorm1 = nn.BatchNorm2d(self.d1)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.dropout2d1 = nn.Dropout2d(0.8)\n",
    "        # (16, 30, 80)\n",
    "        \n",
    "        self.d2 = 32\n",
    "        self.conv2 = nn.Conv2d(self.d1, self.d2, kernel_size=3, stride=1, padding=1, padding_mode='replicate')\n",
    "        # (32, 30, 80)\n",
    "        self.batchNorm2 = nn.BatchNorm2d(self.d2)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.dropout2d2 = nn.Dropout2d(0.8)\n",
    "        # (32, 15, 40)\n",
    "        \n",
    "        self.d3 = 64\n",
    "        self.conv3 = nn.Conv2d(self.d2, self.d3, kernel_size=3, stride=1, padding=1, padding_mode='replicate')\n",
    "        # (64, 15, 40)\n",
    "        self.batchNorm3 = nn.BatchNorm2d(self.d3)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.dropout2d3 = nn.Dropout2d(0.8)\n",
    "        # (64, 7, 20)\n",
    "        \n",
    "        self.d4 = 64\n",
    "        self.conv4 = nn.Conv2d(self.d3, self.d4, kernel_size=3, stride=1, padding=1, padding_mode='replicate')\n",
    "        # (64, 7, 20)\n",
    "        self.batchNorm4 = nn.BatchNorm2d(self.d4)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "        self.dropout2d4 = nn.Dropout2d(0.8)\n",
    "        # (64, 3, 10)\n",
    "        \n",
    "        self.fc1 = nn.Linear(1920, 16)\n",
    "        self.dropout1 = nn.Dropout(0.8)\n",
    "        self.fc2 = nn.Linear(16, 16)\n",
    "        self.dropout2 = nn.Dropout(0.8)\n",
    "        self.fc3 = nn.Linear(16, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchNorm1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout2d1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.batchNorm2(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2d2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.batchNorm3(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.dropout2d3(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.batchNorm4(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pool4(x)\n",
    "        x = self.dropout2d4(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        #x = self.dropout1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.act(x)\n",
    "        #x = self.dropout2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2913,  0.0265,  0.0283],\n",
       "        [-0.0601, -0.3508, -0.2329]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model = Net()\n",
    "test_model.forward(torch.ones(2, 1, 60, 160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[144, 16, 16, 16, 4608, 32, 32, 32, 18432, 64, 64, 64, 36864, 64, 64, 64, 30720, 16, 256, 16, 48, 3]\n"
     ]
    }
   ],
   "source": [
    "print([param.numel() for param in test_model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/57600 (0%)]\tLoss: 21.445341\n",
      "Train Epoch: 1 [2560/57600 (4%)]\tLoss: 5.862597\n",
      "Train Epoch: 1 [5120/57600 (9%)]\tLoss: 6.304902\n",
      "Train Epoch: 1 [7680/57600 (13%)]\tLoss: 4.844772\n",
      "Train Epoch: 1 [10240/57600 (18%)]\tLoss: 4.192564\n",
      "Train Epoch: 1 [12800/57600 (22%)]\tLoss: 5.290054\n",
      "Train Epoch: 1 [15360/57600 (27%)]\tLoss: 4.228281\n",
      "Train Epoch: 1 [17920/57600 (31%)]\tLoss: 4.005170\n",
      "Train Epoch: 1 [20480/57600 (36%)]\tLoss: 3.643368\n",
      "Train Epoch: 1 [23040/57600 (40%)]\tLoss: 4.686207\n",
      "Train Epoch: 1 [25600/57600 (44%)]\tLoss: 3.138190\n",
      "Train Epoch: 1 [28160/57600 (49%)]\tLoss: 3.246668\n",
      "Train Epoch: 1 [30720/57600 (53%)]\tLoss: 2.960124\n",
      "Train Epoch: 1 [33280/57600 (58%)]\tLoss: 3.179504\n",
      "Train Epoch: 1 [35840/57600 (62%)]\tLoss: 3.028437\n",
      "Train Epoch: 1 [38400/57600 (67%)]\tLoss: 2.908184\n",
      "Train Epoch: 1 [40960/57600 (71%)]\tLoss: 3.091822\n",
      "Train Epoch: 1 [43520/57600 (76%)]\tLoss: 2.709124\n",
      "Train Epoch: 1 [46080/57600 (80%)]\tLoss: 3.339944\n",
      "Train Epoch: 1 [48640/57600 (84%)]\tLoss: 2.705128\n",
      "Train Epoch: 1 [51200/57600 (89%)]\tLoss: 2.640156\n",
      "Train Epoch: 1 [53760/57600 (93%)]\tLoss: 2.732386\n",
      "Train Epoch: 1 [56320/57600 (98%)]\tLoss: 2.672004\n",
      "Validation set: Average loss: 6.8500\n",
      "\n",
      "Train Epoch: 2 [0/57600 (0%)]\tLoss: 2.529474\n",
      "Train Epoch: 2 [2560/57600 (4%)]\tLoss: 2.921264\n",
      "Train Epoch: 2 [5120/57600 (9%)]\tLoss: 2.980185\n",
      "Train Epoch: 2 [7680/57600 (13%)]\tLoss: 2.438246\n",
      "Train Epoch: 2 [10240/57600 (18%)]\tLoss: 2.600758\n",
      "Train Epoch: 2 [12800/57600 (22%)]\tLoss: 2.425839\n",
      "Train Epoch: 2 [15360/57600 (27%)]\tLoss: 2.055290\n",
      "Train Epoch: 2 [17920/57600 (31%)]\tLoss: 2.630542\n",
      "Train Epoch: 2 [20480/57600 (36%)]\tLoss: 2.451098\n",
      "Train Epoch: 2 [23040/57600 (40%)]\tLoss: 2.007304\n",
      "Train Epoch: 2 [25600/57600 (44%)]\tLoss: 2.592180\n",
      "Train Epoch: 2 [28160/57600 (49%)]\tLoss: 2.533446\n",
      "Train Epoch: 2 [30720/57600 (53%)]\tLoss: 2.359658\n",
      "Train Epoch: 2 [33280/57600 (58%)]\tLoss: 2.412776\n",
      "Train Epoch: 2 [35840/57600 (62%)]\tLoss: 2.731139\n",
      "Train Epoch: 2 [38400/57600 (67%)]\tLoss: 2.703749\n",
      "Train Epoch: 2 [40960/57600 (71%)]\tLoss: 2.226109\n",
      "Train Epoch: 2 [43520/57600 (76%)]\tLoss: 2.191231\n",
      "Train Epoch: 2 [46080/57600 (80%)]\tLoss: 2.369524\n",
      "Train Epoch: 2 [48640/57600 (84%)]\tLoss: 2.231441\n",
      "Train Epoch: 2 [51200/57600 (89%)]\tLoss: 2.381979\n",
      "Train Epoch: 2 [53760/57600 (93%)]\tLoss: 2.273195\n",
      "Train Epoch: 2 [56320/57600 (98%)]\tLoss: 2.316535\n",
      "Validation set: Average loss: 5.3472\n",
      "\n",
      "Train Epoch: 3 [0/57600 (0%)]\tLoss: 2.141538\n",
      "Train Epoch: 3 [2560/57600 (4%)]\tLoss: 2.214674\n",
      "Train Epoch: 3 [5120/57600 (9%)]\tLoss: 2.153194\n",
      "Train Epoch: 3 [7680/57600 (13%)]\tLoss: 2.520885\n",
      "Train Epoch: 3 [10240/57600 (18%)]\tLoss: 2.080601\n",
      "Train Epoch: 3 [12800/57600 (22%)]\tLoss: 1.766174\n",
      "Train Epoch: 3 [15360/57600 (27%)]\tLoss: 2.149573\n",
      "Train Epoch: 3 [17920/57600 (31%)]\tLoss: 2.089427\n",
      "Train Epoch: 3 [20480/57600 (36%)]\tLoss: 2.083427\n",
      "Train Epoch: 3 [23040/57600 (40%)]\tLoss: 2.067771\n",
      "Train Epoch: 3 [25600/57600 (44%)]\tLoss: 2.159995\n",
      "Train Epoch: 3 [28160/57600 (49%)]\tLoss: 1.896876\n",
      "Train Epoch: 3 [30720/57600 (53%)]\tLoss: 2.179355\n",
      "Train Epoch: 3 [33280/57600 (58%)]\tLoss: 1.810732\n",
      "Train Epoch: 3 [35840/57600 (62%)]\tLoss: 1.925127\n",
      "Train Epoch: 3 [38400/57600 (67%)]\tLoss: 1.616092\n",
      "Train Epoch: 3 [40960/57600 (71%)]\tLoss: 1.976035\n",
      "Train Epoch: 3 [43520/57600 (76%)]\tLoss: 2.046107\n",
      "Train Epoch: 3 [46080/57600 (80%)]\tLoss: 1.626032\n",
      "Train Epoch: 3 [48640/57600 (84%)]\tLoss: 1.697673\n",
      "Train Epoch: 3 [51200/57600 (89%)]\tLoss: 1.662429\n",
      "Train Epoch: 3 [53760/57600 (93%)]\tLoss: 1.673813\n",
      "Train Epoch: 3 [56320/57600 (98%)]\tLoss: 1.438146\n",
      "Validation set: Average loss: 3.4884\n",
      "\n",
      "Train Epoch: 4 [0/57600 (0%)]\tLoss: 1.707176\n",
      "Train Epoch: 4 [2560/57600 (4%)]\tLoss: 1.693306\n",
      "Train Epoch: 4 [5120/57600 (9%)]\tLoss: 1.820163\n",
      "Train Epoch: 4 [7680/57600 (13%)]\tLoss: 1.587348\n",
      "Train Epoch: 4 [10240/57600 (18%)]\tLoss: 1.622510\n",
      "Train Epoch: 4 [12800/57600 (22%)]\tLoss: 1.400011\n",
      "Train Epoch: 4 [15360/57600 (27%)]\tLoss: 1.787663\n",
      "Train Epoch: 4 [17920/57600 (31%)]\tLoss: 1.609916\n",
      "Train Epoch: 4 [20480/57600 (36%)]\tLoss: 1.874590\n",
      "Train Epoch: 4 [23040/57600 (40%)]\tLoss: 2.010216\n",
      "Train Epoch: 4 [25600/57600 (44%)]\tLoss: 2.010027\n",
      "Train Epoch: 4 [28160/57600 (49%)]\tLoss: 1.913450\n",
      "Train Epoch: 4 [30720/57600 (53%)]\tLoss: 1.612870\n",
      "Train Epoch: 4 [33280/57600 (58%)]\tLoss: 1.810360\n",
      "Train Epoch: 4 [35840/57600 (62%)]\tLoss: 1.650375\n",
      "Train Epoch: 4 [38400/57600 (67%)]\tLoss: 1.251591\n",
      "Train Epoch: 4 [40960/57600 (71%)]\tLoss: 1.550174\n",
      "Train Epoch: 4 [43520/57600 (76%)]\tLoss: 1.319191\n",
      "Train Epoch: 4 [46080/57600 (80%)]\tLoss: 1.478133\n",
      "Train Epoch: 4 [48640/57600 (84%)]\tLoss: 1.391245\n",
      "Train Epoch: 4 [51200/57600 (89%)]\tLoss: 1.817861\n",
      "Train Epoch: 4 [53760/57600 (93%)]\tLoss: 1.558239\n",
      "Train Epoch: 4 [56320/57600 (98%)]\tLoss: 1.398356\n",
      "Validation set: Average loss: 2.7777\n",
      "\n",
      "Train Epoch: 5 [0/57600 (0%)]\tLoss: 1.121201\n",
      "Train Epoch: 5 [2560/57600 (4%)]\tLoss: 1.756882\n",
      "Train Epoch: 5 [5120/57600 (9%)]\tLoss: 1.908547\n",
      "Train Epoch: 5 [7680/57600 (13%)]\tLoss: 1.406107\n",
      "Train Epoch: 5 [10240/57600 (18%)]\tLoss: 2.250058\n",
      "Train Epoch: 5 [12800/57600 (22%)]\tLoss: 1.503595\n",
      "Train Epoch: 5 [15360/57600 (27%)]\tLoss: 1.377468\n",
      "Train Epoch: 5 [17920/57600 (31%)]\tLoss: 1.229185\n",
      "Train Epoch: 5 [20480/57600 (36%)]\tLoss: 1.344019\n",
      "Train Epoch: 5 [23040/57600 (40%)]\tLoss: 1.142726\n",
      "Train Epoch: 5 [25600/57600 (44%)]\tLoss: 1.142323\n",
      "Train Epoch: 5 [28160/57600 (49%)]\tLoss: 1.218701\n",
      "Train Epoch: 5 [30720/57600 (53%)]\tLoss: 1.443782\n",
      "Train Epoch: 5 [33280/57600 (58%)]\tLoss: 1.351216\n",
      "Train Epoch: 5 [35840/57600 (62%)]\tLoss: 1.620587\n",
      "Train Epoch: 5 [38400/57600 (67%)]\tLoss: 1.190033\n",
      "Train Epoch: 5 [40960/57600 (71%)]\tLoss: 1.306848\n",
      "Train Epoch: 5 [43520/57600 (76%)]\tLoss: 1.341821\n",
      "Train Epoch: 5 [46080/57600 (80%)]\tLoss: 1.359234\n",
      "Train Epoch: 5 [48640/57600 (84%)]\tLoss: 1.201598\n",
      "Train Epoch: 5 [51200/57600 (89%)]\tLoss: 1.248456\n",
      "Train Epoch: 5 [53760/57600 (93%)]\tLoss: 1.558722\n",
      "Train Epoch: 5 [56320/57600 (98%)]\tLoss: 1.055512\n",
      "Validation set: Average loss: 2.2832\n",
      "\n",
      "Train Epoch: 6 [0/57600 (0%)]\tLoss: 1.243977\n",
      "Train Epoch: 6 [2560/57600 (4%)]\tLoss: 1.474378\n",
      "Train Epoch: 6 [5120/57600 (9%)]\tLoss: 1.322102\n",
      "Train Epoch: 6 [7680/57600 (13%)]\tLoss: 1.224987\n",
      "Train Epoch: 6 [10240/57600 (18%)]\tLoss: 1.239234\n",
      "Train Epoch: 6 [12800/57600 (22%)]\tLoss: 1.185437\n",
      "Train Epoch: 6 [15360/57600 (27%)]\tLoss: 1.260799\n",
      "Train Epoch: 6 [17920/57600 (31%)]\tLoss: 1.159107\n",
      "Train Epoch: 6 [20480/57600 (36%)]\tLoss: 1.420387\n",
      "Train Epoch: 6 [23040/57600 (40%)]\tLoss: 1.122436\n",
      "Train Epoch: 6 [25600/57600 (44%)]\tLoss: 1.568489\n",
      "Train Epoch: 6 [28160/57600 (49%)]\tLoss: 1.324943\n",
      "Train Epoch: 6 [30720/57600 (53%)]\tLoss: 1.156509\n",
      "Train Epoch: 6 [33280/57600 (58%)]\tLoss: 1.226844\n",
      "Train Epoch: 6 [35840/57600 (62%)]\tLoss: 1.173502\n",
      "Train Epoch: 6 [38400/57600 (67%)]\tLoss: 1.436983\n",
      "Train Epoch: 6 [40960/57600 (71%)]\tLoss: 1.312497\n",
      "Train Epoch: 6 [43520/57600 (76%)]\tLoss: 1.213135\n",
      "Train Epoch: 6 [46080/57600 (80%)]\tLoss: 1.228569\n",
      "Train Epoch: 6 [48640/57600 (84%)]\tLoss: 1.426199\n",
      "Train Epoch: 6 [51200/57600 (89%)]\tLoss: 1.327531\n",
      "Train Epoch: 6 [53760/57600 (93%)]\tLoss: 1.233365\n",
      "Train Epoch: 6 [56320/57600 (98%)]\tLoss: 1.082384\n",
      "Validation set: Average loss: 3.3569\n",
      "\n",
      "Train Epoch: 7 [0/57600 (0%)]\tLoss: 1.345699\n",
      "Train Epoch: 7 [2560/57600 (4%)]\tLoss: 1.121060\n",
      "Train Epoch: 7 [5120/57600 (9%)]\tLoss: 1.267697\n",
      "Train Epoch: 7 [7680/57600 (13%)]\tLoss: 1.328677\n",
      "Train Epoch: 7 [10240/57600 (18%)]\tLoss: 1.100750\n",
      "Train Epoch: 7 [12800/57600 (22%)]\tLoss: 1.628697\n",
      "Train Epoch: 7 [15360/57600 (27%)]\tLoss: 1.096576\n",
      "Train Epoch: 7 [17920/57600 (31%)]\tLoss: 1.159377\n",
      "Train Epoch: 7 [20480/57600 (36%)]\tLoss: 1.332322\n",
      "Train Epoch: 7 [23040/57600 (40%)]\tLoss: 0.952184\n",
      "Train Epoch: 7 [25600/57600 (44%)]\tLoss: 1.294807\n",
      "Train Epoch: 7 [28160/57600 (49%)]\tLoss: 1.204956\n",
      "Train Epoch: 7 [30720/57600 (53%)]\tLoss: 1.172977\n",
      "Train Epoch: 7 [33280/57600 (58%)]\tLoss: 1.121302\n",
      "Train Epoch: 7 [35840/57600 (62%)]\tLoss: 1.013632\n",
      "Train Epoch: 7 [38400/57600 (67%)]\tLoss: 1.104942\n",
      "Train Epoch: 7 [40960/57600 (71%)]\tLoss: 1.161131\n",
      "Train Epoch: 7 [43520/57600 (76%)]\tLoss: 1.320820\n",
      "Train Epoch: 7 [46080/57600 (80%)]\tLoss: 1.295760\n",
      "Train Epoch: 7 [48640/57600 (84%)]\tLoss: 1.002041\n",
      "Train Epoch: 7 [51200/57600 (89%)]\tLoss: 0.939579\n",
      "Train Epoch: 7 [53760/57600 (93%)]\tLoss: 1.030539\n",
      "Train Epoch: 7 [56320/57600 (98%)]\tLoss: 1.484273\n",
      "Validation set: Average loss: 1.9107\n",
      "\n",
      "Train Epoch: 8 [0/57600 (0%)]\tLoss: 1.114384\n",
      "Train Epoch: 8 [2560/57600 (4%)]\tLoss: 0.979990\n",
      "Train Epoch: 8 [5120/57600 (9%)]\tLoss: 1.343014\n",
      "Train Epoch: 8 [7680/57600 (13%)]\tLoss: 0.942223\n",
      "Train Epoch: 8 [10240/57600 (18%)]\tLoss: 1.186331\n",
      "Train Epoch: 8 [12800/57600 (22%)]\tLoss: 1.077960\n",
      "Train Epoch: 8 [15360/57600 (27%)]\tLoss: 1.329043\n",
      "Train Epoch: 8 [17920/57600 (31%)]\tLoss: 1.078760\n",
      "Train Epoch: 8 [20480/57600 (36%)]\tLoss: 1.169277\n",
      "Train Epoch: 8 [23040/57600 (40%)]\tLoss: 1.174596\n",
      "Train Epoch: 8 [25600/57600 (44%)]\tLoss: 1.136790\n",
      "Train Epoch: 8 [28160/57600 (49%)]\tLoss: 0.976071\n",
      "Train Epoch: 8 [30720/57600 (53%)]\tLoss: 1.109628\n",
      "Train Epoch: 8 [33280/57600 (58%)]\tLoss: 1.076070\n",
      "Train Epoch: 8 [35840/57600 (62%)]\tLoss: 1.137794\n",
      "Train Epoch: 8 [38400/57600 (67%)]\tLoss: 1.150830\n",
      "Train Epoch: 8 [40960/57600 (71%)]\tLoss: 0.923338\n",
      "Train Epoch: 8 [43520/57600 (76%)]\tLoss: 0.941508\n",
      "Train Epoch: 8 [46080/57600 (80%)]\tLoss: 0.990331\n",
      "Train Epoch: 8 [48640/57600 (84%)]\tLoss: 0.860430\n",
      "Train Epoch: 8 [51200/57600 (89%)]\tLoss: 1.223075\n",
      "Train Epoch: 8 [53760/57600 (93%)]\tLoss: 1.270915\n",
      "Train Epoch: 8 [56320/57600 (98%)]\tLoss: 1.015741\n",
      "Validation set: Average loss: 2.0380\n",
      "\n",
      "Train Epoch: 9 [0/57600 (0%)]\tLoss: 1.060237\n",
      "Train Epoch: 9 [2560/57600 (4%)]\tLoss: 1.305115\n",
      "Train Epoch: 9 [5120/57600 (9%)]\tLoss: 0.945996\n",
      "Train Epoch: 9 [7680/57600 (13%)]\tLoss: 1.026232\n",
      "Train Epoch: 9 [10240/57600 (18%)]\tLoss: 1.073157\n",
      "Train Epoch: 9 [12800/57600 (22%)]\tLoss: 0.857995\n",
      "Train Epoch: 9 [15360/57600 (27%)]\tLoss: 0.912188\n",
      "Train Epoch: 9 [17920/57600 (31%)]\tLoss: 1.151367\n",
      "Train Epoch: 9 [20480/57600 (36%)]\tLoss: 0.992334\n",
      "Train Epoch: 9 [23040/57600 (40%)]\tLoss: 0.997962\n",
      "Train Epoch: 9 [25600/57600 (44%)]\tLoss: 1.091282\n",
      "Train Epoch: 9 [28160/57600 (49%)]\tLoss: 0.845074\n",
      "Train Epoch: 9 [30720/57600 (53%)]\tLoss: 1.162239\n",
      "Train Epoch: 9 [33280/57600 (58%)]\tLoss: 0.983290\n",
      "Train Epoch: 9 [35840/57600 (62%)]\tLoss: 0.874038\n",
      "Train Epoch: 9 [38400/57600 (67%)]\tLoss: 1.016234\n",
      "Train Epoch: 9 [40960/57600 (71%)]\tLoss: 0.957056\n",
      "Train Epoch: 9 [43520/57600 (76%)]\tLoss: 1.058141\n",
      "Train Epoch: 9 [46080/57600 (80%)]\tLoss: 0.959335\n",
      "Train Epoch: 9 [48640/57600 (84%)]\tLoss: 0.854802\n",
      "Train Epoch: 9 [51200/57600 (89%)]\tLoss: 1.036215\n",
      "Train Epoch: 9 [53760/57600 (93%)]\tLoss: 0.827156\n",
      "Train Epoch: 9 [56320/57600 (98%)]\tLoss: 1.223755\n",
      "Validation set: Average loss: 1.7667\n",
      "\n",
      "Train Epoch: 10 [0/57600 (0%)]\tLoss: 0.940338\n",
      "Train Epoch: 10 [2560/57600 (4%)]\tLoss: 0.828098\n",
      "Train Epoch: 10 [5120/57600 (9%)]\tLoss: 1.304023\n",
      "Train Epoch: 10 [7680/57600 (13%)]\tLoss: 1.015456\n",
      "Train Epoch: 10 [10240/57600 (18%)]\tLoss: 0.923153\n",
      "Train Epoch: 10 [12800/57600 (22%)]\tLoss: 0.882612\n",
      "Train Epoch: 10 [15360/57600 (27%)]\tLoss: 1.011271\n",
      "Train Epoch: 10 [17920/57600 (31%)]\tLoss: 0.921983\n",
      "Train Epoch: 10 [20480/57600 (36%)]\tLoss: 0.994858\n",
      "Train Epoch: 10 [23040/57600 (40%)]\tLoss: 0.976688\n",
      "Train Epoch: 10 [25600/57600 (44%)]\tLoss: 0.880602\n",
      "Train Epoch: 10 [28160/57600 (49%)]\tLoss: 0.915147\n",
      "Train Epoch: 10 [30720/57600 (53%)]\tLoss: 0.998777\n",
      "Train Epoch: 10 [33280/57600 (58%)]\tLoss: 0.787066\n",
      "Train Epoch: 10 [35840/57600 (62%)]\tLoss: 0.866585\n",
      "Train Epoch: 10 [38400/57600 (67%)]\tLoss: 1.130826\n",
      "Train Epoch: 10 [40960/57600 (71%)]\tLoss: 0.799287\n",
      "Train Epoch: 10 [43520/57600 (76%)]\tLoss: 1.187652\n",
      "Train Epoch: 10 [46080/57600 (80%)]\tLoss: 0.906920\n",
      "Train Epoch: 10 [48640/57600 (84%)]\tLoss: 0.813193\n",
      "Train Epoch: 10 [51200/57600 (89%)]\tLoss: 1.031491\n",
      "Train Epoch: 10 [53760/57600 (93%)]\tLoss: 1.168901\n",
      "Train Epoch: 10 [56320/57600 (98%)]\tLoss: 1.012406\n",
      "Validation set: Average loss: 1.6627\n",
      "\n",
      "Train Epoch: 11 [0/57600 (0%)]\tLoss: 0.798172\n",
      "Train Epoch: 11 [2560/57600 (4%)]\tLoss: 0.968986\n",
      "Train Epoch: 11 [5120/57600 (9%)]\tLoss: 0.895434\n",
      "Train Epoch: 11 [7680/57600 (13%)]\tLoss: 1.162533\n",
      "Train Epoch: 11 [10240/57600 (18%)]\tLoss: 1.018792\n",
      "Train Epoch: 11 [12800/57600 (22%)]\tLoss: 1.071610\n",
      "Train Epoch: 11 [15360/57600 (27%)]\tLoss: 0.790526\n",
      "Train Epoch: 11 [17920/57600 (31%)]\tLoss: 0.833318\n",
      "Train Epoch: 11 [20480/57600 (36%)]\tLoss: 0.990547\n",
      "Train Epoch: 11 [23040/57600 (40%)]\tLoss: 0.982620\n",
      "Train Epoch: 11 [25600/57600 (44%)]\tLoss: 0.841000\n",
      "Train Epoch: 11 [28160/57600 (49%)]\tLoss: 1.147047\n",
      "Train Epoch: 11 [30720/57600 (53%)]\tLoss: 0.919129\n",
      "Train Epoch: 11 [33280/57600 (58%)]\tLoss: 0.941591\n",
      "Train Epoch: 11 [35840/57600 (62%)]\tLoss: 0.764689\n",
      "Train Epoch: 11 [38400/57600 (67%)]\tLoss: 0.890104\n",
      "Train Epoch: 11 [40960/57600 (71%)]\tLoss: 0.714975\n",
      "Train Epoch: 11 [43520/57600 (76%)]\tLoss: 0.964972\n",
      "Train Epoch: 11 [46080/57600 (80%)]\tLoss: 0.935892\n",
      "Train Epoch: 11 [48640/57600 (84%)]\tLoss: 0.973897\n",
      "Train Epoch: 11 [51200/57600 (89%)]\tLoss: 0.882435\n",
      "Train Epoch: 11 [53760/57600 (93%)]\tLoss: 0.719208\n",
      "Train Epoch: 11 [56320/57600 (98%)]\tLoss: 1.073881\n",
      "Validation set: Average loss: 1.7096\n",
      "\n",
      "Train Epoch: 12 [0/57600 (0%)]\tLoss: 0.982447\n",
      "Train Epoch: 12 [2560/57600 (4%)]\tLoss: 1.076374\n",
      "Train Epoch: 12 [5120/57600 (9%)]\tLoss: 0.707773\n",
      "Train Epoch: 12 [7680/57600 (13%)]\tLoss: 1.148468\n",
      "Train Epoch: 12 [10240/57600 (18%)]\tLoss: 0.856341\n",
      "Train Epoch: 12 [12800/57600 (22%)]\tLoss: 1.002920\n",
      "Train Epoch: 12 [15360/57600 (27%)]\tLoss: 1.066215\n",
      "Train Epoch: 12 [17920/57600 (31%)]\tLoss: 0.829137\n",
      "Train Epoch: 12 [20480/57600 (36%)]\tLoss: 0.963472\n",
      "Train Epoch: 12 [23040/57600 (40%)]\tLoss: 1.011132\n",
      "Train Epoch: 12 [25600/57600 (44%)]\tLoss: 0.859733\n",
      "Train Epoch: 12 [28160/57600 (49%)]\tLoss: 0.854118\n",
      "Train Epoch: 12 [30720/57600 (53%)]\tLoss: 1.002902\n",
      "Train Epoch: 12 [33280/57600 (58%)]\tLoss: 0.904741\n",
      "Train Epoch: 12 [35840/57600 (62%)]\tLoss: 0.817346\n",
      "Train Epoch: 12 [38400/57600 (67%)]\tLoss: 0.968278\n",
      "Train Epoch: 12 [40960/57600 (71%)]\tLoss: 0.845235\n",
      "Train Epoch: 12 [43520/57600 (76%)]\tLoss: 0.867497\n",
      "Train Epoch: 12 [46080/57600 (80%)]\tLoss: 1.112354\n",
      "Train Epoch: 12 [48640/57600 (84%)]\tLoss: 0.804610\n",
      "Train Epoch: 12 [51200/57600 (89%)]\tLoss: 0.763163\n",
      "Train Epoch: 12 [53760/57600 (93%)]\tLoss: 0.977005\n",
      "Train Epoch: 12 [56320/57600 (98%)]\tLoss: 1.124763\n",
      "Validation set: Average loss: 1.5563\n",
      "\n",
      "Train Epoch: 13 [0/57600 (0%)]\tLoss: 0.962937\n",
      "Train Epoch: 13 [2560/57600 (4%)]\tLoss: 0.817843\n",
      "Train Epoch: 13 [5120/57600 (9%)]\tLoss: 0.849954\n",
      "Train Epoch: 13 [7680/57600 (13%)]\tLoss: 0.931742\n",
      "Train Epoch: 13 [10240/57600 (18%)]\tLoss: 1.121863\n",
      "Train Epoch: 13 [12800/57600 (22%)]\tLoss: 0.870784\n",
      "Train Epoch: 13 [15360/57600 (27%)]\tLoss: 0.808992\n",
      "Train Epoch: 13 [17920/57600 (31%)]\tLoss: 0.799606\n",
      "Train Epoch: 13 [20480/57600 (36%)]\tLoss: 0.941738\n",
      "Train Epoch: 13 [23040/57600 (40%)]\tLoss: 0.988505\n",
      "Train Epoch: 13 [25600/57600 (44%)]\tLoss: 0.939530\n",
      "Train Epoch: 13 [28160/57600 (49%)]\tLoss: 0.729068\n",
      "Train Epoch: 13 [30720/57600 (53%)]\tLoss: 1.145667\n",
      "Train Epoch: 13 [33280/57600 (58%)]\tLoss: 1.052336\n",
      "Train Epoch: 13 [35840/57600 (62%)]\tLoss: 0.798245\n",
      "Train Epoch: 13 [38400/57600 (67%)]\tLoss: 0.923893\n",
      "Train Epoch: 13 [40960/57600 (71%)]\tLoss: 0.649365\n",
      "Train Epoch: 13 [43520/57600 (76%)]\tLoss: 0.813402\n",
      "Train Epoch: 13 [46080/57600 (80%)]\tLoss: 0.798251\n",
      "Train Epoch: 13 [48640/57600 (84%)]\tLoss: 0.843668\n",
      "Train Epoch: 13 [51200/57600 (89%)]\tLoss: 0.982019\n",
      "Train Epoch: 13 [53760/57600 (93%)]\tLoss: 0.824892\n",
      "Train Epoch: 13 [56320/57600 (98%)]\tLoss: 0.949456\n",
      "Validation set: Average loss: 1.4911\n",
      "\n",
      "Train Epoch: 14 [0/57600 (0%)]\tLoss: 0.916967\n",
      "Train Epoch: 14 [2560/57600 (4%)]\tLoss: 0.893032\n",
      "Train Epoch: 14 [5120/57600 (9%)]\tLoss: 0.700323\n",
      "Train Epoch: 14 [7680/57600 (13%)]\tLoss: 0.797645\n",
      "Train Epoch: 14 [10240/57600 (18%)]\tLoss: 0.563925\n",
      "Train Epoch: 14 [12800/57600 (22%)]\tLoss: 0.818806\n",
      "Train Epoch: 14 [15360/57600 (27%)]\tLoss: 0.777275\n",
      "Train Epoch: 14 [17920/57600 (31%)]\tLoss: 1.064456\n",
      "Train Epoch: 14 [20480/57600 (36%)]\tLoss: 0.686013\n",
      "Train Epoch: 14 [23040/57600 (40%)]\tLoss: 0.775318\n",
      "Train Epoch: 14 [25600/57600 (44%)]\tLoss: 0.895000\n",
      "Train Epoch: 14 [28160/57600 (49%)]\tLoss: 0.763654\n",
      "Train Epoch: 14 [30720/57600 (53%)]\tLoss: 0.880257\n",
      "Train Epoch: 14 [33280/57600 (58%)]\tLoss: 0.863072\n",
      "Train Epoch: 14 [35840/57600 (62%)]\tLoss: 0.926221\n",
      "Train Epoch: 14 [38400/57600 (67%)]\tLoss: 0.899264\n",
      "Train Epoch: 14 [40960/57600 (71%)]\tLoss: 0.933656\n",
      "Train Epoch: 14 [43520/57600 (76%)]\tLoss: 0.784672\n",
      "Train Epoch: 14 [46080/57600 (80%)]\tLoss: 0.834230\n",
      "Train Epoch: 14 [48640/57600 (84%)]\tLoss: 0.647906\n",
      "Train Epoch: 14 [51200/57600 (89%)]\tLoss: 0.896461\n",
      "Train Epoch: 14 [53760/57600 (93%)]\tLoss: 0.847853\n",
      "Train Epoch: 14 [56320/57600 (98%)]\tLoss: 0.765353\n",
      "Validation set: Average loss: 1.5284\n",
      "\n",
      "Train Epoch: 15 [0/57600 (0%)]\tLoss: 0.701812\n",
      "Train Epoch: 15 [2560/57600 (4%)]\tLoss: 0.896670\n",
      "Train Epoch: 15 [5120/57600 (9%)]\tLoss: 0.906519\n",
      "Train Epoch: 15 [7680/57600 (13%)]\tLoss: 0.619582\n",
      "Train Epoch: 15 [10240/57600 (18%)]\tLoss: 1.008007\n",
      "Train Epoch: 15 [12800/57600 (22%)]\tLoss: 0.905042\n",
      "Train Epoch: 15 [15360/57600 (27%)]\tLoss: 0.612700\n",
      "Train Epoch: 15 [17920/57600 (31%)]\tLoss: 0.776242\n",
      "Train Epoch: 15 [20480/57600 (36%)]\tLoss: 0.800271\n",
      "Train Epoch: 15 [23040/57600 (40%)]\tLoss: 0.790926\n",
      "Train Epoch: 15 [25600/57600 (44%)]\tLoss: 1.034428\n",
      "Train Epoch: 15 [28160/57600 (49%)]\tLoss: 0.791210\n",
      "Train Epoch: 15 [30720/57600 (53%)]\tLoss: 0.889365\n",
      "Train Epoch: 15 [33280/57600 (58%)]\tLoss: 0.790985\n",
      "Train Epoch: 15 [35840/57600 (62%)]\tLoss: 0.962121\n",
      "Train Epoch: 15 [38400/57600 (67%)]\tLoss: 0.938539\n",
      "Train Epoch: 15 [40960/57600 (71%)]\tLoss: 0.690879\n",
      "Train Epoch: 15 [43520/57600 (76%)]\tLoss: 0.881467\n",
      "Train Epoch: 15 [46080/57600 (80%)]\tLoss: 0.905820\n",
      "Train Epoch: 15 [48640/57600 (84%)]\tLoss: 0.926535\n",
      "Train Epoch: 15 [51200/57600 (89%)]\tLoss: 0.757867\n",
      "Train Epoch: 15 [53760/57600 (93%)]\tLoss: 0.808463\n",
      "Train Epoch: 15 [56320/57600 (98%)]\tLoss: 1.207805\n",
      "Validation set: Average loss: 1.5300\n",
      "\n",
      "Train Epoch: 16 [0/57600 (0%)]\tLoss: 0.925369\n",
      "Train Epoch: 16 [2560/57600 (4%)]\tLoss: 0.944449\n",
      "Train Epoch: 16 [5120/57600 (9%)]\tLoss: 1.032068\n",
      "Train Epoch: 16 [7680/57600 (13%)]\tLoss: 0.753775\n",
      "Train Epoch: 16 [10240/57600 (18%)]\tLoss: 0.831772\n",
      "Train Epoch: 16 [12800/57600 (22%)]\tLoss: 0.874584\n",
      "Train Epoch: 16 [15360/57600 (27%)]\tLoss: 0.900353\n",
      "Train Epoch: 16 [17920/57600 (31%)]\tLoss: 0.791456\n",
      "Train Epoch: 16 [20480/57600 (36%)]\tLoss: 0.990343\n",
      "Train Epoch: 16 [23040/57600 (40%)]\tLoss: 0.804316\n",
      "Train Epoch: 16 [25600/57600 (44%)]\tLoss: 0.692760\n",
      "Train Epoch: 16 [28160/57600 (49%)]\tLoss: 0.622661\n",
      "Train Epoch: 16 [30720/57600 (53%)]\tLoss: 0.724131\n",
      "Train Epoch: 16 [33280/57600 (58%)]\tLoss: 0.939400\n",
      "Train Epoch: 16 [35840/57600 (62%)]\tLoss: 0.866623\n",
      "Train Epoch: 16 [38400/57600 (67%)]\tLoss: 0.861274\n",
      "Train Epoch: 16 [40960/57600 (71%)]\tLoss: 0.757615\n",
      "Train Epoch: 16 [43520/57600 (76%)]\tLoss: 0.899957\n",
      "Train Epoch: 16 [46080/57600 (80%)]\tLoss: 0.816114\n",
      "Train Epoch: 16 [48640/57600 (84%)]\tLoss: 0.865012\n",
      "Train Epoch: 16 [51200/57600 (89%)]\tLoss: 0.836022\n",
      "Train Epoch: 16 [53760/57600 (93%)]\tLoss: 0.724384\n",
      "Train Epoch: 16 [56320/57600 (98%)]\tLoss: 0.672076\n",
      "Validation set: Average loss: 1.3629\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Load your model [fcNet, ConvNet, Net]\n",
    "model = Net().to(device)\n",
    "\n",
    "# Try different optimzers here [Adam, SGD, RMSprop]\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n",
    "\n",
    "# Set your learning rate scheduler\n",
    "scheduler = StepLR(optimizer, step_size=args.step, gamma=1)\n",
    "\n",
    "# Training loop\n",
    "args.epochs = 16\n",
    "train_loss = np.zeros((args.epochs,))\n",
    "val_loss = np.zeros((args.epochs,))\n",
    "for epoch in range(args.epochs):\n",
    "    train(args, model, device, train_loader, optimizer, epoch, reg_lambda=args.reg_lambda, verbose=True)\n",
    "    #train_loss[epoch] = test(model, device, train_loader, name='Training')\n",
    "    val_loss[epoch] = test(model, device, val_loader, name='Validation')\n",
    "    print()\n",
    "    scheduler.step()    # learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), os.path.join(path_outputs, 'best_conv.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]),\n",
       " array([1.4006294 , 0.13216238, 3.413782  ], dtype=float32))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    model.eval()    # Set the model to inference mode\n",
    "    test_loss = 0.\n",
    "    with torch.no_grad():   # For the inference step, gradient is not computed\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.mse_loss(output, target, reduction='sum').item()  # sum up batch loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
