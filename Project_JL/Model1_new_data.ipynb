{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rc('image', cmap='gray')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from EyeTracking import EyeTrackingDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                    help='input batch size for training (default: 64)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                    help='input batch size for testing (default: 1000)')\n",
    "parser.add_argument('--validation-percentage', type=float, default=15., metavar='P',\n",
    "                   help='percentage of training data used for validation')\n",
    "# parser.add_argument('--training-division', type=float, default=1., metavar='D',\n",
    "#                    help='divide the remaining training data by this factor')\n",
    "parser.add_argument('--epochs', type=int, default=14, metavar='N',\n",
    "                    help='number of epochs to train (default: 14)')\n",
    "parser.add_argument('--lr', type=float, default=1.0, metavar='LR',\n",
    "                    help='learning rate (default: 1.0)')\n",
    "parser.add_argument('--step', type=int, default=1, metavar='N',\n",
    "                    help='number of epochs between learning rate reductions (default: 1)')\n",
    "parser.add_argument('--gamma', type=float, default=0.7, metavar='M',\n",
    "                    help='Learning rate step gamma (default: 0.7)')\n",
    "parser.add_argument('--reg-lambda', type=float, default=0.001, metavar='L',\n",
    "                    help='Regularization lambda (default:0.001)')\n",
    "parser.add_argument('--no-cuda', action='store_true',\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-numbers', type=int, default=10, metavar='N',\n",
    "                    help='how many entries of logging training status to show per epoch')\n",
    "parser.add_argument('--evaluate', action='store_true',\n",
    "                    help='evaluate your model on the official test set')\n",
    "parser.add_argument('--load-model', type=str,\n",
    "                    help='model file path')\n",
    "parser.add_argument('--save-model', type=str,\n",
    "                    help='For Saving the current Model');\n",
    "\n",
    "args = parser.parse_args('--validation-percentage 10 --batch-size 128 --epochs 8 --lr 1 --step 1 --gamma 0.9 --reg-lambda 0.0008 --seed 2020 --log-numbers 20'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(args.seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "path_outputs = '../data/project'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_images = r'E:\\Data\\Unity\\Minos\\images'\n",
    "path_pos = r'E:\\Data\\Unity\\Minos\\pos.bin'\n",
    "dataset = EyeTrackingDataset(path_pos, dir_images, transform=transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize(60),\n",
    "    transforms.ColorJitter(brightness=0.05, contrast=0.05),\n",
    "    transforms.ToTensor()\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 32000 samples and divided into 28800 training and 3200 validation samples\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(args.seed)\n",
    "idc = rng.permutation(len(dataset))\n",
    "n_train = np.round(len(dataset)*(1-args.validation_percentage/100)).astype(int)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset, batch_size=args.batch_size,\n",
    "    sampler=SubsetRandomSampler(idc[:n_train]), **kwargs\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset, batch_size=args.batch_size,\n",
    "    sampler=SubsetRandomSampler(idc[n_train:]), **kwargs\n",
    ")\n",
    "\n",
    "print(f'Loaded {len(dataset)} samples and divided into {len(train_loader.sampler)} training and {len(val_loader.sampler)} validation samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.17859761  0.12360682  0.33589324  1.        ]\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(dataset[0][0].numpy().squeeze())\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "print(dataset[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch, reg_lambda=0.001, verbose=True):\n",
    "    '''\n",
    "    This is your training function. When you call this function, the model is\n",
    "    trained for 1 epoch.\n",
    "    '''\n",
    "    model.train()   # Set the model to training mode\n",
    "    for batch_idx, (data, target, ref) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()               # Clear the gradient\n",
    "        output = model(data)                # Make predictions\n",
    "        loss = F.mse_loss(output[:, 0:3], target[:, 0:3])   # Compute loss\n",
    "        for param in model.parameters():    # Compute regularization\n",
    "            loss += reg_lambda*torch.mean(torch.abs(param))\n",
    "        loss.backward()                     # Gradient computation\n",
    "        optimizer.step()                    # Perform a single optimization step\n",
    "        if batch_idx % args.log_numbers == 0 and verbose:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch+1, batch_idx * len(data), len(train_loader.sampler),\n",
    "                100. * batch_idx * len(data) / len(train_loader.sampler), loss.item()))\n",
    "\n",
    "def test(model, device, test_loader, name='Validation', verbose=True):\n",
    "    model.eval()    # Set the model to inference mode\n",
    "    test_loss = 0.\n",
    "    with torch.no_grad():   # For the inference step, gradient is not computed\n",
    "        for data, target, ref in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.mse_loss(output[:, 0:3], target[:, 0:3], reduction='sum').item()  # sum up batch loss\n",
    "\n",
    "    test_loss /= len(test_loader.sampler)\n",
    "    \n",
    "    if verbose:\n",
    "        print('{:s} set: Average loss: {:.4f}'.format(\n",
    "            name, test_loss))\n",
    "    \n",
    "    return test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.act = nn.ELU()\n",
    "        # (1, 60, 160)\n",
    "        \n",
    "        self.d1 = 16\n",
    "        self.conv1 = nn.Conv2d(1, self.d1, kernel_size=3, stride=1, padding=1, padding_mode='replicate')\n",
    "        # (16, 60, 160)\n",
    "        self.batchNorm1 = nn.BatchNorm2d(self.d1)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.dropout2d1 = nn.Dropout2d(0.8)\n",
    "        # (16, 30, 80)\n",
    "        \n",
    "        self.d2 = 32\n",
    "        self.conv2 = nn.Conv2d(self.d1, self.d2, kernel_size=3, stride=1, padding=1, padding_mode='replicate')\n",
    "        # (32, 30, 80)\n",
    "        self.batchNorm2 = nn.BatchNorm2d(self.d2)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.dropout2d2 = nn.Dropout2d(0.8)\n",
    "        # (32, 15, 40)\n",
    "        \n",
    "        self.d3 = 64\n",
    "        self.conv3 = nn.Conv2d(self.d2, self.d3, kernel_size=3, stride=1, padding=1, padding_mode='replicate')\n",
    "        # (64, 15, 40)\n",
    "        self.batchNorm3 = nn.BatchNorm2d(self.d3)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.dropout2d3 = nn.Dropout2d(0.8)\n",
    "        # (64, 7, 20)\n",
    "        \n",
    "        self.d4 = 64\n",
    "        self.conv4 = nn.Conv2d(self.d3, self.d4, kernel_size=3, stride=1, padding=1, padding_mode='replicate')\n",
    "        # (64, 7, 20)\n",
    "        self.batchNorm4 = nn.BatchNorm2d(self.d4)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "        self.dropout2d4 = nn.Dropout2d(0.8)\n",
    "        # (64, 3, 10)\n",
    "        \n",
    "        self.fc1 = nn.Linear(1920, 16)\n",
    "        self.dropout1 = nn.Dropout(0.8)\n",
    "        self.fc2 = nn.Linear(16, 16)\n",
    "        self.dropout2 = nn.Dropout(0.8)\n",
    "        self.fc3 = nn.Linear(16, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchNorm1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout2d1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.batchNorm2(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2d2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.batchNorm3(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.dropout2d3(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.batchNorm4(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pool4(x)\n",
    "        x = self.dropout2d4(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        #x = self.dropout1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.act(x)\n",
    "        #x = self.dropout2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1194, -0.7815, -0.2506, -0.4324],\n",
       "        [ 0.1857, -0.6533, -0.4283, -0.3018]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model = Net()\n",
    "test_model.forward(torch.ones(2, 1, 60, 160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[144, 16, 16, 16, 4608, 32, 32, 32, 18432, 64, 64, 64, 36864, 64, 64, 64, 30720, 16, 256, 16, 64, 4]\n"
     ]
    }
   ],
   "source": [
    "print([param.numel() for param in test_model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/28800 (0%)]\tLoss: 11.665172\n",
      "Train Epoch: 1 [2560/28800 (9%)]\tLoss: 5.278293\n",
      "Train Epoch: 1 [5120/28800 (18%)]\tLoss: 4.419567\n",
      "Train Epoch: 1 [7680/28800 (27%)]\tLoss: 3.915037\n",
      "Train Epoch: 1 [10240/28800 (36%)]\tLoss: 3.630218\n",
      "Train Epoch: 1 [12800/28800 (44%)]\tLoss: 3.805866\n",
      "Train Epoch: 1 [15360/28800 (53%)]\tLoss: 3.775404\n",
      "Train Epoch: 1 [17920/28800 (62%)]\tLoss: 3.635144\n",
      "Train Epoch: 1 [20480/28800 (71%)]\tLoss: 3.805530\n",
      "Train Epoch: 1 [23040/28800 (80%)]\tLoss: 3.736947\n",
      "Train Epoch: 1 [25600/28800 (89%)]\tLoss: 3.894907\n",
      "Train Epoch: 1 [28160/28800 (98%)]\tLoss: 3.501870\n",
      "Validation set: Average loss: 10.5646\n",
      "\n",
      "Train Epoch: 2 [0/28800 (0%)]\tLoss: 3.433202\n",
      "Train Epoch: 2 [2560/28800 (9%)]\tLoss: 3.557285\n",
      "Train Epoch: 2 [5120/28800 (18%)]\tLoss: 4.279489\n",
      "Train Epoch: 2 [7680/28800 (27%)]\tLoss: 4.028799\n",
      "Train Epoch: 2 [10240/28800 (36%)]\tLoss: 3.824893\n",
      "Train Epoch: 2 [12800/28800 (44%)]\tLoss: 3.714304\n",
      "Train Epoch: 2 [15360/28800 (53%)]\tLoss: 3.302579\n",
      "Train Epoch: 2 [17920/28800 (62%)]\tLoss: 3.346799\n",
      "Train Epoch: 2 [20480/28800 (71%)]\tLoss: 3.218194\n",
      "Train Epoch: 2 [23040/28800 (80%)]\tLoss: 4.190197\n",
      "Train Epoch: 2 [25600/28800 (89%)]\tLoss: 3.797855\n",
      "Train Epoch: 2 [28160/28800 (98%)]\tLoss: 3.571376\n",
      "Validation set: Average loss: 10.4755\n",
      "\n",
      "Train Epoch: 3 [0/28800 (0%)]\tLoss: 3.567923\n",
      "Train Epoch: 3 [2560/28800 (9%)]\tLoss: 3.619468\n",
      "Train Epoch: 3 [5120/28800 (18%)]\tLoss: 3.516547\n",
      "Train Epoch: 3 [7680/28800 (27%)]\tLoss: 3.308991\n",
      "Train Epoch: 3 [10240/28800 (36%)]\tLoss: 3.369814\n",
      "Train Epoch: 3 [12800/28800 (44%)]\tLoss: 3.692832\n",
      "Train Epoch: 3 [15360/28800 (53%)]\tLoss: 3.387570\n",
      "Train Epoch: 3 [17920/28800 (62%)]\tLoss: 3.884317\n",
      "Train Epoch: 3 [20480/28800 (71%)]\tLoss: 3.599499\n",
      "Train Epoch: 3 [23040/28800 (80%)]\tLoss: 3.728652\n",
      "Train Epoch: 3 [25600/28800 (89%)]\tLoss: 3.373893\n",
      "Train Epoch: 3 [28160/28800 (98%)]\tLoss: 3.457891\n",
      "Validation set: Average loss: 10.4333\n",
      "\n",
      "Train Epoch: 4 [0/28800 (0%)]\tLoss: 3.545529\n",
      "Train Epoch: 4 [2560/28800 (9%)]\tLoss: 3.660446\n",
      "Train Epoch: 4 [5120/28800 (18%)]\tLoss: 3.264946\n",
      "Train Epoch: 4 [7680/28800 (27%)]\tLoss: 3.543054\n",
      "Train Epoch: 4 [10240/28800 (36%)]\tLoss: 3.784623\n",
      "Train Epoch: 4 [12800/28800 (44%)]\tLoss: 3.714810\n",
      "Train Epoch: 4 [15360/28800 (53%)]\tLoss: 3.099382\n",
      "Train Epoch: 4 [17920/28800 (62%)]\tLoss: 3.667261\n",
      "Train Epoch: 4 [20480/28800 (71%)]\tLoss: 3.213815\n",
      "Train Epoch: 4 [23040/28800 (80%)]\tLoss: 3.385084\n",
      "Train Epoch: 4 [25600/28800 (89%)]\tLoss: 3.253528\n",
      "Train Epoch: 4 [28160/28800 (98%)]\tLoss: 3.743253\n",
      "Validation set: Average loss: 10.4402\n",
      "\n",
      "Train Epoch: 5 [0/28800 (0%)]\tLoss: 3.621476\n",
      "Train Epoch: 5 [2560/28800 (9%)]\tLoss: 3.467437\n",
      "Train Epoch: 5 [5120/28800 (18%)]\tLoss: 3.818674\n",
      "Train Epoch: 5 [7680/28800 (27%)]\tLoss: 3.653828\n",
      "Train Epoch: 5 [10240/28800 (36%)]\tLoss: 3.026266\n",
      "Train Epoch: 5 [12800/28800 (44%)]\tLoss: 3.164857\n",
      "Train Epoch: 5 [15360/28800 (53%)]\tLoss: 3.669954\n",
      "Train Epoch: 5 [17920/28800 (62%)]\tLoss: 3.486561\n",
      "Train Epoch: 5 [20480/28800 (71%)]\tLoss: 3.806299\n",
      "Train Epoch: 5 [23040/28800 (80%)]\tLoss: 3.731490\n",
      "Train Epoch: 5 [25600/28800 (89%)]\tLoss: 3.745347\n",
      "Train Epoch: 5 [28160/28800 (98%)]\tLoss: 3.760984\n",
      "Validation set: Average loss: 10.4243\n",
      "\n",
      "Train Epoch: 6 [0/28800 (0%)]\tLoss: 3.853040\n",
      "Train Epoch: 6 [2560/28800 (9%)]\tLoss: 3.814905\n",
      "Train Epoch: 6 [5120/28800 (18%)]\tLoss: 3.202868\n",
      "Train Epoch: 6 [7680/28800 (27%)]\tLoss: 3.773593\n",
      "Train Epoch: 6 [10240/28800 (36%)]\tLoss: 3.252895\n",
      "Train Epoch: 6 [12800/28800 (44%)]\tLoss: 3.393619\n",
      "Train Epoch: 6 [15360/28800 (53%)]\tLoss: 3.446158\n",
      "Train Epoch: 6 [17920/28800 (62%)]\tLoss: 3.682431\n",
      "Train Epoch: 6 [20480/28800 (71%)]\tLoss: 3.421363\n",
      "Train Epoch: 6 [23040/28800 (80%)]\tLoss: 3.840857\n",
      "Train Epoch: 6 [25600/28800 (89%)]\tLoss: 3.890006\n",
      "Train Epoch: 6 [28160/28800 (98%)]\tLoss: 3.829970\n",
      "Validation set: Average loss: 10.3759\n",
      "\n",
      "Train Epoch: 7 [0/28800 (0%)]\tLoss: 3.325193\n",
      "Train Epoch: 7 [2560/28800 (9%)]\tLoss: 3.718708\n",
      "Train Epoch: 7 [5120/28800 (18%)]\tLoss: 4.010710\n",
      "Train Epoch: 7 [7680/28800 (27%)]\tLoss: 3.942688\n",
      "Train Epoch: 7 [10240/28800 (36%)]\tLoss: 3.507175\n",
      "Train Epoch: 7 [12800/28800 (44%)]\tLoss: 3.731192\n",
      "Train Epoch: 7 [15360/28800 (53%)]\tLoss: 3.537971\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-2b988d606d0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg_lambda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreg_lambda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[1;31m#train_loss[epoch] = test(model, device, train_loader, name='Training')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Validation'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-e01e43dc10fd>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(args, model, device, train_loader, optimizer, epoch, reg_lambda, verbose)\u001b[0m\n\u001b[0;32m      5\u001b[0m     '''\n\u001b[0;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# Set the model to training mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m               \u001b[1;31m# Clear the gradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\vision\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\vision\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    839\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\vision\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    796\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 798\u001b[1;33m                 \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    799\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\vision\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    759\u001b[0m         \u001b[1;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 761\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    762\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\vision\\lib\\queue.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    177\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\vision\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Load your model [fcNet, ConvNet, Net]\n",
    "model = Net().to(device)\n",
    "\n",
    "# Try different optimzers here [Adam, SGD, RMSprop]\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n",
    "\n",
    "# Set your learning rate scheduler\n",
    "scheduler = StepLR(optimizer, step_size=args.step, gamma=1)\n",
    "\n",
    "# Training loop\n",
    "args.epochs = 16\n",
    "train_loss = np.zeros((args.epochs,))\n",
    "val_loss = np.zeros((args.epochs,))\n",
    "for epoch in range(args.epochs):\n",
    "    train(args, model, device, train_loader, optimizer, epoch, reg_lambda=args.reg_lambda, verbose=True)\n",
    "    #train_loss[epoch] = test(model, device, train_loader, name='Training')\n",
    "    val_loss[epoch] = test(model, device, val_loader, name='Validation')\n",
    "    print()\n",
    "    scheduler.step()    # learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), os.path.join(path_outputs, 'cnn1.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()    # Set the model to inference mode\n",
    "val_target = None\n",
    "val_output = None\n",
    "with torch.no_grad():   # For the inference step, gradient is not computed\n",
    "    for data, target in val_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        if val_target is None:\n",
    "            val_target = target.cpu().numpy()\n",
    "        else:\n",
    "            val_target = np.vstack((val_target, target.cpu().numpy()))\n",
    "        if val_output is None:\n",
    "            val_output = output.cpu().numpy()\n",
    "        else:\n",
    "            val_output = np.vstack((val_output, output.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_target.shape, val_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_diff = val_output-val_target\n",
    "val_result = np.dstack((val_target, val_output))\n",
    "print(val_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "fig = plt.figure(figsize=(20, 15), tight_layout=True)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for k in range(200):\n",
    "    ax.plot(val_result[k, 0, :], val_result[k, 1, :], val_result[k, 2, :])\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('z')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(path_outputs, 'val_loss1.npy'), val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
